---
title: Core Principles and Architecture for Building Agentic AI
description: What is "minimal core + tool bootstrapping"? Why is the coding agent the core form of Agentic AI? And how to build a Claude Code-like product with the A3S Code TypeScript SDK.
date: "2026-02-27"
author: A3S Lab
tags: [a3s-code, coding-agent, architecture, typescript, sdk]
---

Software development is the highest-density test of AI Agent capability. Reading an unfamiliar codebase, tracking down a subtle bug, adding new functionality without breaking existing logic — these tasks require an Agent to simultaneously perceive, reason, act, and verify. Miss any one of them and the Agent fails.

That's why the coding agent isn't just a vertical application of AI — it's the core form of the entire Agentic AI field. This post explains the core principles of building Agentic AI from an architectural perspective, introduces the "minimal core + tool bootstrapping" design pattern, compares the positioning of three mainstream tools, and then demonstrates how to build a Claude Code-like product from scratch using the A3S Code TypeScript SDK.

---

## I. The Essence of an Agent: The Perceive–Decide–Act Loop

Strip away the outer shell of any AI Agent and you're left with three layers:

**Perception** — reading environment state. File contents, command output, API responses, database records — all are the Agent's perception targets.

**Decision** — reasoning about the next step based on state. This is the LLM's core job: given the current context, decide which tool to call and with what arguments.

**Action** — executing tool calls to produce side effects. Writing files, running commands, calling APIs — changing the state of the external world.

These three layers form a loop. Each iteration is called a "turn." An Agent's capability is fundamentally the quality of this loop: how accurate the perception, how sound the reasoning, how reliable the action, how timely the feedback.

A codebase is the best training ground for this loop, because it provides **objective feedback signals**. The compiler either passes or errors. Tests are either green or red. No ambiguity. This objectivity lets the Agent self-correct without depending on human judgment.

An Agent that can work autonomously in a codebase already has the foundational capabilities to work in any other structured environment.

---

## II. Minimal Core + Tool Bootstrapping

This is the most important architectural principle for building Agentic AI systems, and the design foundation of A3S Code.

### What is a minimal core?

A minimal core means: **the non-replaceable parts of the system should be as small as possible.**

The true core of a coding Agent is only five components:

```
Agent          ← Configuration loading, session lifecycle management
AgentSession   ← Workspace-bound execution context
AgentLoop      ← Execution engine driving LLM turns
ToolExecutor   ← Tool registration, dispatch, execution
LlmClient      ← Unified abstraction over LLM providers
```

These five components are the skeleton of the system. Their relationships are fixed: `Agent` creates `AgentSession`, `AgentSession` holds `AgentLoop`, `AgentLoop` calls `LlmClient` for decisions each turn, then executes tools through `ToolExecutor`.

This skeleton should not change with business requirements. It is stable, testable, and independently reasoned about.

### What is tool bootstrapping?

Tool bootstrapping means: **all of the Agent's extended capabilities are implemented through tools, not by modifying the core.**

This principle has two layers:

**Layer one: built-in tools cover foundational capabilities.** File read/write, code search, command execution, network requests — these are the basic actions of a coding Agent, available as built-in tools, ready out of the box.

**Layer two: external tools extend specialized capabilities.** Database operations, code review, deployment pipelines, third-party APIs — these are integrated via MCP (Model Context Protocol) or custom tools, without touching core code.

The key insight of tool bootstrapping is: **the LLM itself is the best tool router.** You don't need to write complex intent-recognition logic. Just give the LLM clear enough tool descriptions, and it will decide when to use which tool.

The result of this design: the system's capability boundary is determined by the tool set, and the tool set can be dynamically extended at runtime, while core code stays unchanged.

### Why does this principle matter?

Consider the opposite: what happens if you bake permission control, memory management, skills systems, and MCP integration into the core?

The core becomes bloated. Every new requirement requires modifying the core. Different features become coupled. Testing becomes difficult. Maintenance cost grows exponentially.

Minimal core + tool bootstrapping dissolves all of these problems: the core does one thing (drive LLM turns), everything else is a pluggable extension.

In A3S Code, this principle manifests as 19 trait extension points, each with a default implementation:

```typescript
// Not happy with the default permission system? Implement your own.
class MyPermissionChecker implements PermissionChecker {
  async check(tool: string, args: unknown): Promise<Permission> {
    // your logic
  }
}

const session = agent.session('.', {
  permissionChecker: new MyPermissionChecker(),
});
```

Works out of the box. Any part is replaceable. Core stays stable.

---

## III. A3S Code's Full Capability Boundary

Minimal core + tool bootstrapping is the architectural principle, but A3S Code's actual capability boundary goes much further. Here's a systematic overview of all core features — memory system, context retrieval, hooks, security layer, planner, and more.

### 3.1 Memory System: Long-Term Memory Across Sessions

`MemoryStore` lets the Agent retain key information across multiple sessions. Unlike `SessionStore` (which saves conversation history), `MemoryStore` stores **distilled knowledge** — user preferences, project context, important decisions.

```typescript
import { MemoryStore, Memory } from '@a3s-lab/code';

class VectorMemoryStore implements MemoryStore {
  async save(memory: Memory): Promise<void> {
    // Store in a vector database (e.g. Pinecone, Qdrant)
    await vectorDB.upsert({
      id: memory.id,
      vector: await embed(memory.content),
      metadata: { timestamp: memory.timestamp, tags: memory.tags },
    });
  }

  async search(query: string, limit: number): Promise<Memory[]> {
    // Semantic search for relevant memories
    const results = await vectorDB.query(await embed(query), limit);
    return results.map((r) => ({
      id: r.id,
      content: r.metadata.content,
      timestamp: r.metadata.timestamp,
      tags: r.metadata.tags,
    }));
  }
}

const session = agent.session('.', {
  memoryStore: new VectorMemoryStore(),
});

// Agent automatically retrieves relevant context from memory
await session.stream('Continue the refactoring task from last time');
// → Agent retrieves: "Last refactoring goal: migrate auth module to JWT"
```

### 3.2 Context Retrieval (RAG): Dynamically Inject External Knowledge

`ContextProvider` automatically retrieves relevant documents before each turn and injects them into the LLM context. This is the standard RAG (Retrieval-Augmented Generation) implementation.

```typescript
import { ContextProvider, ContextChunk } from '@a3s-lab/code';

class CodebaseContextProvider implements ContextProvider {
  async retrieve(query: string, maxChunks: number): Promise<ContextChunk[]> {
    // Retrieve relevant code snippets from the codebase index
    const results = await codeSearch.search(query, maxChunks);
    return results.map((r) => ({
      content: r.code,
      source: r.filePath,
      score: r.relevance,
    }));
  }
}

const session = agent.session('.', {
  contextProvider: new CodebaseContextProvider(),
});

// User question triggers automatic retrieval
await session.stream('Where is the JWT validation logic in the auth module?');
// → ContextProvider retrieves relevant code from src/auth/jwt.ts
// → LLM answers based on the retrieved code
```

### 3.3 Hooks System: Event-Driven Automation

Hooks execute automatically before and after tool calls, for logging, auditing, and automated workflows.

```typescript
import { HookHandler, ToolCallEvent, ToolResultEvent } from '@a3s-lab/code';

class AuditHookHandler implements HookHandler {
  async onToolCall(event: ToolCallEvent): Promise<void> {
    // Before tool call: write audit log
    await auditLog.write({
      timestamp: Date.now(),
      tool: event.tool,
      args: event.args,
      sessionId: event.sessionId,
    });

    // High-risk operations: send notification
    if (['bash', 'write', 'delete'].includes(event.tool)) {
      await slack.notify(`⚠️ Agent is executing ${event.tool}`);
    }
  }

  async onToolResult(event: ToolResultEvent): Promise<void> {
    // After tool call: record result
    await auditLog.write({
      timestamp: Date.now(),
      tool: event.tool,
      success: !event.result.isError,
      duration: event.duration,
    });
  }
}

const session = agent.session('.', {
  hookHandler: new AuditHookHandler(),
});
```

### 3.4 Security Layer: Input Taint Analysis and Output Sanitization

`SecurityProvider` detects malicious content in inputs before tool execution, and sanitizes sensitive information from outputs.

```typescript
import { SecurityProvider, TaintAnalysis, SanitizeResult } from '@a3s-lab/code';

class ProductionSecurityProvider implements SecurityProvider {
  async analyzeTaint(input: string): Promise<TaintAnalysis> {
    // Detect command injection, path traversal, SQL injection
    const threats = [];
    if (/;\s*(rm|curl|wget|nc)\s/.test(input)) threats.push('command_injection');
    if (/\.\.[\/\\]/.test(input)) threats.push('path_traversal');
    if (/(union|select|drop|insert)\s+/i.test(input)) threats.push('sql_injection');

    return {
      isTainted: threats.length > 0,
      threats,
      riskLevel: threats.length > 0 ? 'high' : 'low',
    };
  }

  async sanitizeOutput(output: string): Promise<SanitizeResult> {
    // Remove sensitive data: API keys, passwords, tokens
    let sanitized = output;
    sanitized = sanitized.replace(/sk-[a-zA-Z0-9]{48}/g, '[REDACTED_API_KEY]');
    sanitized = sanitized.replace(/password["\s:=]+[^\s"]+/gi, 'password=[REDACTED]');
    sanitized = sanitized.replace(/Bearer\s+[^\s]+/g, 'Bearer [REDACTED]');

    return { sanitized, redacted: sanitized !== output };
  }
}

const session = agent.session('.', {
  securityProvider: new ProductionSecurityProvider(),
});
```

### 3.5 Planner: Automatic Decomposition of Complex Tasks

`Planner` breaks complex tasks into a sequence of sub-tasks that the Agent executes step by step.

```typescript
import { Planner, Task, Plan } from '@a3s-lab/code';

class HierarchicalPlanner implements Planner {
  async plan(goal: string, context: string): Promise<Plan> {
    // Use LLM to generate task decomposition
    const response = await llm.complete({
      prompt: `Goal: ${goal}\nContext: ${context}\n\nDecompose into an executable sequence of sub-tasks.`,
    });

    const tasks: Task[] = parseTasksFromResponse(response);
    return { goal, tasks, estimatedSteps: tasks.length };
  }
}

const session = agent.session('.', {
  planner: new HierarchicalPlanner(),
});

// Complex task is automatically decomposed
await session.stream('Refactor the entire auth module to use JWT with refresh tokens, update all tests');
// → Planner decomposes into:
//   1. Read existing auth code
//   2. Design JWT + refresh token approach
//   3. Implement new auth logic
//   4. Update tests
//   5. Verify all tests pass
```

### 3.6 Context Compaction: Automatic Token Budget Management

When conversation history exceeds a threshold, `ContextCompactor` automatically compresses old turns while preserving key information.

```hcl
# agent.hcl
context_compaction {
  enabled           = true
  trigger_threshold = 100000  # trigger at 100k tokens
  target_size       = 50000   # compress to 50k tokens
  strategy          = "semantic"  # semantic compression (preserve key info)
}
```

Compaction strategies:
- **Truncate**: drop the oldest turns directly
- **Summarize**: use LLM to summarize old turns, keep the summary
- **Semantic**: retain the most relevant turns based on semantic similarity

### 3.7 Multi-Language SDKs: Rust / Node.js / Python

A3S Code is a Rust core library with Node.js and Python native bindings via FFI.

**Rust API** (zero overhead, maximum performance):

```rust
use a3s_code::{Agent, Event};
use futures::StreamExt;

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let agent = Agent::new("agent.hcl").await?;
    let session = agent.session("/project", None)?;

    let mut stream = session.stream("Refactor the auth module").await?;
    while let Some(event) = stream.next().await {
        match event {
            Event::TextDelta(text) => print!("{}", text),
            Event::ToolUse(tool) => println!("\n[{}]", tool.name),
            Event::End => println!(),
            _ => {}
        }
    }
    Ok(())
}
```

**Python SDK** (async-first, type hints):

```python
from a3s_code import Agent, SessionLane
import asyncio

async def main():
    agent = await Agent.create("agent.hcl")
    session = agent.session(".", tools=finance_tools)

    # Parallel research
    tasks = [
        {"prompt": f"Analyze {sym}", "lane": SessionLane.GENERATE}
        for sym in ["AAPL", "MSFT", "NVDA"]
    ]
    results = await session.submit_batch(tasks)
    print(results)

asyncio.run(main())
```

### 3.8 Feature Summary

| Feature | Purpose | Extension Point |
|---------|---------|----------------|
| **Memory system** | Long-term memory across sessions | `MemoryStore` |
| **Context retrieval** | RAG dynamic knowledge injection | `ContextProvider` |
| **Hooks** | Event-driven automation | `HookHandler` |
| **Security layer** | Input taint analysis, output sanitization | `SecurityProvider` |
| **Planner** | Complex task decomposition | `Planner` |
| **Context compaction** | Automatic token budget management | Config-driven |
| **Multi-language SDKs** | Rust / Node.js / Python | Native bindings |

All of these features are **optional extensions** — the system ships with default implementations and works out of the box. To customize, implement the corresponding trait. Core code stays unchanged.

---

## IV. Three Positions, Three Design Philosophies

Three tools deserve serious comparison: Claude Code, OpenCode, and A3S Code. All carry the "coding Agent" label, but their underlying design philosophies are completely different.

### Claude Code: Developer Experience First

Claude Code is an interactive CLI tool built by Anthropic, designed to **give developers the best AI-assisted programming experience in the terminal**.

Its design philosophy is "human-machine collaboration": the Agent proposes a plan, the human approves, the Agent executes, the human observes. The entire interaction flow is designed around this rhythm — permission prompts, plan mode, HITL confirmation — all to keep the human in control.

This positioning determines its architectural choices: it's a CLI tool, not a library. You use it through the terminal; you can't call it through code. It's bound to Anthropic's models, because Anthropic can do deep optimization for its own models (context compression, tool call format, system prompt design).

**The boundary of this positioning**: when you need to embed coding Agent capability into your own product, Claude Code can't help. It has no programming API, no multi-tenancy support, and wasn't designed for programmatic invocation.

### OpenCode: Open Ecosystem First

OpenCode is an open-source terminal coding Agent, designed to **provide a model-agnostic, self-hostable alternative to Claude Code**.

Its design philosophy is "openness first": supports any OpenAI-compatible model endpoint, fully open-source, community can contribute features and integrations.

This positioning determines its architectural choices: it's also a CLI tool, with interactive terminal experience at its core. Its advantage is flexibility — you can connect local models, privately deployed models, any compatible API.

**The boundary of this positioning**: like Claude Code, its architecture centers on "human-machine interaction" and wasn't designed for programmatic embedding. If you want to call it from your application, you're dealing with a CLI tool, not an SDK.

### OpenClaw: Personal Assistant Experience First

OpenClaw is a personal AI assistant Agent for messaging platforms (WhatsApp, Telegram, Slack), designed to **give users intelligent task automation inside the chat tools they already use every day**.

Its design philosophy is "conversation as operation": users issue instructions in natural language, the Agent understands intent and executes — querying information, managing schedules, processing files, calling external services. The entire experience is designed around the interaction paradigm of messaging platforms, not terminals or IDEs.

This positioning determines its architectural choices: it's a service deployed on messaging platforms, not a local tool or embeddable library. Its advantage is reach — users don't need to install anything; AI capability is available inside their existing chat tools.

**The boundary of this positioning**: its core is "personal assistant," not "coding agent." When you need to embed Agent capability into your own product, or handle codebase-level complex tasks, its architecture wasn't designed for those scenarios.

### A3S Code: Embeddability First

A3S Code solves a completely different problem: **when you need to embed coding Agent capability as infrastructure into your product, what do you use?**

Its design philosophy is "library first": Rust core library + Node.js/Python native bindings — not a service, not a CLI, but a library your code can call directly.

This positioning determines its architectural choices: minimal core + tool bootstrapping, 19 trait extension points, lane priority queue, multi-machine task dispatch, MCP runtime dynamic registration. Every design decision answers the same question: how do we make this library run reliably in production?

**The boundary of this positioning**: it's not an out-of-the-box terminal tool. You need to write code to integrate it. If you just want AI-assisted programming in the terminal, Claude Code is the better choice.

### Positioning Comparison

| | Claude Code | OpenCode | OpenClaw | A3S Code |
|---|---|---|---|---|
| **Core positioning** | Developer terminal tool | Open ecosystem terminal tool | Messaging platform personal assistant | Embeddable Agent infrastructure |
| **Usage** | CLI interaction | CLI interaction | Messaging platform conversation | Code invocation |
| **Model support** | Anthropic (+ Bedrock/Vertex) | Any OpenAI-compatible | Multi-model | Any OpenAI-compatible |
| **Embeddability** | No programming API | No programming API | No programming API | Core design goal |
| **Extension** | MCP + Skills + Hooks | MCP + plugins | Plugins | Trait extension points + MCP |
| **Multi-tenancy** | Not supported | Not supported | Not supported | Supported |
| **Parallel tasks** | Sub-agent parallelism | Limited | Not supported | Lane queue + multi-machine dispatch |
| **Open source** | No | Yes | Yes | Yes |

This isn't a comparison of feature quality — it's a comparison of design goals. All four tools have their own value within their respective positioning.

---

## V. Building a Claude Code-Like Product with the TypeScript SDK

With the architectural principles understood, let's put them into practice. We'll use the A3S Code TypeScript SDK to build a terminal coding assistant with Claude Code's core capabilities.

Target product features:
- Multi-turn conversation with codebase context understanding
- Streaming output showing the Agent's thinking in real time
- Tool execution (read files, write files, run commands)
- Permission control requiring user confirmation for sensitive operations
- MCP server support for dynamically extending the tool set
- Session persistence supporting resumption of previous conversations

### 4.1 Installation and Configuration

```bash
npm install @a3s-lab/code
```

Create an `agent.hcl` config file:

```hcl
# Supports any OpenAI-compatible endpoint
default_model = "anthropic/claude-sonnet-4-20250514"

providers {
  name    = "anthropic"
  api_key = env("ANTHROPIC_API_KEY")
}

# Optional: connect MCP servers
mcp_servers {
  name    = "filesystem"
  command = "npx"
  args    = ["-y", "@modelcontextprotocol/server-filesystem", "."]
}
```

### 4.2 Core Session Loop

This is the skeleton of the entire product — a loop that reads user input and streams Agent responses:

```typescript
import { Agent } from '@a3s-lab/code';
import * as readline from 'readline';

const agent = await Agent.create('agent.hcl');
const session = agent.session(process.cwd());

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

function prompt(): Promise<string> {
  return new Promise((resolve) => {
    rl.question('\n> ', resolve);
  });
}

console.log('A3S Code — type your question, Ctrl+C to exit\n');

while (true) {
  const input = await prompt();
  if (!input.trim()) continue;

  // Streaming output: show every character the Agent produces in real time
  const events = await session.stream(input);

  for await (const event of events) {
    switch (event.type) {
      case 'text_delta':
        process.stdout.write(event.text);
        break;

      case 'tool_use':
        // Show tool calls so the user knows what the Agent is doing
        console.log(`\n[tool] ${event.tool}(${JSON.stringify(event.args)})`);
        break;

      case 'tool_result':
        // Tool execution complete; optionally show a result summary
        break;

      case 'end':
        console.log('\n');
        break;
    }
  }
}
```

### 4.3 Adding Permission Control

A core design of Claude Code is that dangerous operations require user confirmation. We implement the same effect with A3S Code's permission system:

```typescript
import { Agent, PermissionChecker, Permission } from '@a3s-lab/code';
import * as readline from 'readline';

// High-risk tools that require confirmation
const DANGEROUS_TOOLS = new Set(['bash', 'write', 'edit', 'patch']);

class InteractivePermissionChecker implements PermissionChecker {
  private rl: readline.Interface;

  constructor(rl: readline.Interface) {
    this.rl = rl;
  }

  async check(tool: string, args: unknown): Promise<Permission> {
    // Read-only tools pass through immediately
    if (!DANGEROUS_TOOLS.has(tool)) {
      return Permission.Allow;
    }

    // Show the operation about to be executed
    const preview = this.formatPreview(tool, args);
    console.log(`\n⚠️  Agent wants to execute:\n${preview}`);

    const answer = await new Promise<string>((resolve) => {
      this.rl.question('Allow? [y/N] ', resolve);
    });

    return answer.toLowerCase() === 'y' ? Permission.Allow : Permission.Deny;
  }

  private formatPreview(tool: string, args: unknown): string {
    const a = args as Record<string, unknown>;
    switch (tool) {
      case 'bash':
        return `  $ ${a.command}`;
      case 'write':
        return `  Write file: ${a.file_path}`;
      case 'edit':
        return `  Edit file: ${a.file_path}`;
      default:
        return `  ${tool}: ${JSON.stringify(args, null, 2)}`;
    }
  }
}

// Integrate into session
const session = agent.session(process.cwd(), {
  permissionChecker: new InteractivePermissionChecker(rl),
});
```

### 4.4 Dynamic MCP Server Registration

Claude Code supports declaring MCP servers in config files. A3S Code also supports runtime dynamic registration, letting you load tools on demand based on the user's project type:

```typescript
// Detect project type and load MCP servers on demand
async function loadProjectMcpServers(session: AgentSession, projectPath: string) {
  const fs = await import('fs/promises');

  // Detected package.json → load Node.js-related tools
  try {
    await fs.access(`${projectPath}/package.json`);
    const count = await session.addMcpServer(
      'nodejs-tools',
      'npx',
      ['-y', '@modelcontextprotocol/server-filesystem', projectPath],
    );
    console.log(`[MCP] Loaded Node.js toolset, ${count} tools available`);
  } catch {}

  // Detected Cargo.toml → load Rust-related tools
  try {
    await fs.access(`${projectPath}/Cargo.toml`);
    const count = await session.addMcpServer(
      'rust-tools',
      'npx',
      ['-y', '@modelcontextprotocol/server-filesystem', projectPath],
    );
    console.log(`[MCP] Loaded Rust toolset, ${count} tools available`);
  } catch {}
}
```

### 4.5 Session Persistence

Claude Code supports resuming previous sessions. A3S Code implements the same capability through the `SessionStore` trait:

```typescript
import { SessionStore, SessionData } from '@a3s-lab/code';
import * as fs from 'fs/promises';
import * as path from 'path';

class FileSessionStore implements SessionStore {
  private storePath: string;

  constructor(storePath: string) {
    this.storePath = storePath;
  }

  async save(sessionId: string, data: SessionData): Promise<void> {
    const filePath = path.join(this.storePath, `${sessionId}.json`);
    await fs.mkdir(this.storePath, { recursive: true });
    await fs.writeFile(filePath, JSON.stringify(data, null, 2));
  }

  async load(sessionId: string): Promise<SessionData | null> {
    const filePath = path.join(this.storePath, `${sessionId}.json`);
    try {
      const content = await fs.readFile(filePath, 'utf-8');
      return JSON.parse(content);
    } catch {
      return null;
    }
  }

  async delete(sessionId: string): Promise<void> {
    const filePath = path.join(this.storePath, `${sessionId}.json`);
    await fs.unlink(filePath).catch(() => {});
  }
}

// Use the project directory as session ID for "one session per project"
const projectId = Buffer.from(process.cwd()).toString('base64url');
const session = agent.session(process.cwd(), {
  sessionId: projectId,
  sessionStore: new FileSessionStore(path.join(process.env.HOME!, '.a3s/sessions')),
  permissionChecker: new InteractivePermissionChecker(rl),
});
```

### 4.6 Slash Commands

Claude Code has built-in commands like `/help`, `/clear`, `/cost`. A3S Code's `SlashCommand` interface lets you implement the same:

```typescript
import { SlashCommand, CommandContext, CommandOutput } from '@a3s-lab/code';

// /cost command: show token usage for this session
class CostCommand implements SlashCommand {
  name = 'cost';
  description = 'Show token usage and estimated cost for this session';

  execute(_args: string, ctx: CommandContext): CommandOutput {
    const usage = ctx.tokenUsage;
    // Claude Sonnet 4 pricing (for reference)
    const inputCost = (usage.promptTokens / 1_000_000) * 3.0;
    const outputCost = (usage.completionTokens / 1_000_000) * 15.0;
    const total = inputCost + outputCost;

    return CommandOutput.text(
      `Token usage:\n` +
      `  Input:  ${usage.promptTokens.toLocaleString()} tokens ($${inputCost.toFixed(4)})\n` +
      `  Output: ${usage.completionTokens.toLocaleString()} tokens ($${outputCost.toFixed(4)})\n` +
      `  Total:  $${total.toFixed(4)}`
    );
  }
}

// /clear command: clear conversation history
class ClearCommand implements SlashCommand {
  name = 'clear';
  description = 'Clear conversation history and start a new session';

  execute(_args: string, ctx: CommandContext): CommandOutput {
    ctx.clearHistory();
    return CommandOutput.text('Conversation history cleared');
  }
}

session.registerCommand(new CostCommand());
session.registerCommand(new ClearCommand());
```

### 4.7 Full Product Assembly

Putting it all together:

```typescript
import { Agent } from '@a3s-lab/code';
import * as readline from 'readline';
import * as path from 'path';

async function main() {
  const agent = await Agent.create('agent.hcl');

  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout,
    terminal: true,
  });

  // Handle Ctrl+C
  rl.on('close', () => {
    console.log('\nGoodbye!');
    process.exit(0);
  });

  const projectId = Buffer.from(process.cwd()).toString('base64url');

  const session = agent.session(process.cwd(), {
    sessionId: projectId,
    sessionStore: new FileSessionStore(
      path.join(process.env.HOME!, '.a3s/sessions')
    ),
    permissionChecker: new InteractivePermissionChecker(rl),
  });

  // Register commands
  session.registerCommand(new CostCommand());
  session.registerCommand(new ClearCommand());

  // Load MCP servers on demand
  await loadProjectMcpServers(session, process.cwd());

  // Show welcome message
  const isResumed = await session.hasHistory();
  if (isResumed) {
    console.log('✓ Previous session resumed. Type /clear to start fresh.\n');
  } else {
    console.log('A3S Code — type your question, /help for commands, Ctrl+C to exit\n');
  }

  // Main loop
  while (true) {
    const input = await new Promise<string>((resolve) => {
      rl.question('> ', resolve);
    });

    if (!input.trim()) continue;

    // Slash commands
    if (input.startsWith('/')) {
      const output = await session.executeCommand(input);
      console.log(output.text);
      continue;
    }

    // Agent streaming response
    try {
      const events = await session.stream(input);
      for await (const event of events) {
        if (event.type === 'text_delta') {
          process.stdout.write(event.text);
        } else if (event.type === 'tool_use') {
          process.stdout.write(`\n[${event.tool}] `);
        } else if (event.type === 'end') {
          console.log('\n');
        }
      }
    } catch (err) {
      console.error(`\nError: ${err instanceof Error ? err.message : err}\n`);
    }
  }
}

main().catch(console.error);
```

This product already has Claude Code's core capabilities: multi-turn conversation, streaming output, tool execution, permission control, MCP support, session persistence, and slash commands. Under 200 lines of code.

---

## VI. Building an Agentic Finance Application

The coding agent isn't just a tool for developers — it's the infrastructure for building Agentic applications in any domain. The difference between a real Agentic application and an ordinary chatbot is this: it can autonomously plan, execute in parallel, and coordinate multiple specialized Agents — rather than passively responding to one instruction at a time.

Here we use the A3S Code TypeScript SDK to build a financial research system that demonstrates four core Agentic features: **skills system**, **auto-planning**, **Agent Team**, and **parallel research analysis**.

### 5.1 Skills System: Define Professional Behavior

A skill is a Markdown behavior specification file that tells the Agent what process to follow in a given scenario. It's not code — it's structured professional knowledge.

```markdown
<!-- skills/portfolio_analyst.md -->
# Portfolio Analyst

## Analysis Process

When receiving a portfolio analysis request, **you must** execute the following steps in order
without skipping any:

1. **Data collection**: call get_portfolio for all holdings, call get_quote for live prices
2. **Parallel research**: launch independent analysis tasks for each holding simultaneously
   (use submit_batch)
3. **Risk assessment**: calculate overall portfolio volatility, concentration risk, correlation
4. **Generate report**: output a structured report with holdings overview, risk ratings,
   and rebalancing recommendations

## Report Format

\`\`\`
## Portfolio Analysis Report
**Time**: {timestamp}
**Total Value**: ${total_value}  **Total P&L**: ${total_pnl} ({pnl_pct}%)

### Holdings
| Symbol | Shares | Cost | Price | P&L | Risk |
...

### Risk Assessment
- Concentration: {concentration}
- Highest-risk position: {symbol}
- Recommendation: {recommendation}
\`\`\`

## Notes
- All recommendations must be data-driven, no speculation
- High-risk positions must be explicitly flagged
- Rebalancing suggestions must include rationale
```

Load the skill in HCL config:

```hcl
# agent.hcl
default_model = "anthropic/claude-sonnet-4-20250514"

providers {
  name    = "anthropic"
  api_key = env("ANTHROPIC_API_KEY")
}

skills_dir = "./skills"
```

The value of the skills system is **reusable professional knowledge**: the same analysis process can be loaded by different Agent instances, ensuring behavioral consistency and making it easy for teams to maintain collaboratively.

### 5.2 Auto-Planning: One Sentence Triggers the Full Flow

When the user says "give me a complete portfolio analysis," the Agent doesn't answer directly — it **plans first, then executes**.

```typescript
import { Agent, SessionLane } from '@a3s-lab/code';

const agent = await Agent.create('agent.hcl');

// Load the portfolio analyst skill
const session = agent.session('.', {
  tools: financeTools,
  skills: ['portfolio_analyst'],  // inject professional behavior spec
});

// The user provides one sentence; the Agent automatically plans and executes:
// 1. call get_portfolio to fetch holdings
// 2. call get_quote to batch-fetch prices
// 3. launch parallel research tasks (one per holding)
// 4. aggregate results and generate structured report
const events = await session.stream(
  'Give me a complete portfolio analysis, focusing on risk exposure and rebalancing recommendations'
);

for await (const event of events) {
  if (event.type === 'text_delta') process.stdout.write(event.text);
  else if (event.type === 'tool_use') console.log(`\n→ [${event.tool}]`);
  else if (event.type === 'end') console.log('\n');
}
```

The key here: **the skill file defines the planning logic, and the Agent autonomously decides the call order and tool combinations**. You don't write any orchestration code.

### 5.3 Parallel Research: Analyze Multiple Stocks Simultaneously

Deep research on multiple stocks is slow when done serially. `submitBatch` runs multiple analysis tasks in parallel and aggregates the results.

```typescript
import { Agent, SessionLane } from '@a3s-lab/code';

async function parallelStockResearch(symbols: string[]) {
  const agent = await Agent.create('agent.hcl');
  const session = agent.session('.', { tools: financeTools });

  // Create an independent deep-research task per symbol — all run in parallel
  const researchTasks = symbols.map((sym) => ({
    prompt: `Deep analysis of ${sym}:
      1. Fetch live quote and volume
      2. Assess current risk level
      3. Give a data-driven buy/hold/sell recommendation
      Output structured JSON.`,
    lane: SessionLane.Generate,  // route to Generate lane for parallel execution
  }));

  console.log(`Launching ${symbols.length} parallel research tasks...`);
  const results = await session.submitBatch(researchTasks);

  // Once all tasks complete, pass to a summary Agent for the final report
  const summarySession = agent.session('.', { tools: financeTools });
  const summaryEvents = await summarySession.stream(
    `Here are the independent research results for each stock:\n${JSON.stringify(results, null, 2)}\n\n` +
    `Please synthesize the above into a portfolio optimization report, ` +
    `including risk diversification recommendations and position sizing suggestions.`
  );

  for await (const event of summaryEvents) {
    if (event.type === 'text_delta') process.stdout.write(event.text);
    else if (event.type === 'end') console.log('\n');
  }
}

// Research 4 stocks in parallel — total time ≈ time for a single stock analysis
await parallelStockResearch(['AAPL', 'MSFT', 'NVDA', 'TSLA']);
```

### 5.4 Agent Team: Specialized Collaboration

Complex financial analysis requires different areas of expertise working together. Agent Team lets you assign tasks to specialized Worker Agents, coordinated by a Lead Agent.

```typescript
import { Agent, AgentTeam } from '@a3s-lab/code';

async function buildFinanceTeam() {
  // Lead Agent: receives user requests, plans tasks, delegates to Workers, aggregates results
  const lead = await Agent.create('agent.hcl');
  const leadSession = lead.session('.', {
    tools: financeTools,
    skills: ['portfolio_analyst'],
    role: 'lead',
  });

  // Worker 1: Market Analyst — focused on price data and technical indicators
  const marketAnalyst = await Agent.create('agent.hcl');
  const marketSession = marketAnalyst.session('.', {
    tools: [financeTools.find((t) => t.name === 'get_quote')!],
    systemPrompt: 'You are a market analyst specializing in price data, volume analysis, and price trends.',
    role: 'worker',
    workerId: 'market_analyst',
  });

  // Worker 2: Risk Analyst — focused on risk assessment and stress testing
  const riskAnalyst = await Agent.create('agent.hcl');
  const riskSession = riskAnalyst.session('.', {
    tools: [financeTools.find((t) => t.name === 'risk_assessment')!],
    systemPrompt: 'You are a risk analyst specializing in volatility calculation, risk exposure, and stress testing.',
    role: 'worker',
    workerId: 'risk_analyst',
  });

  // Form the team — Lead can delegate sub-tasks to Workers
  const team = AgentTeam.create({
    lead: leadSession,
    workers: [marketSession, riskSession],
  });

  // Lead receives the user request and automatically decides which sub-tasks go to which Worker.
  // Market data → market_analyst, risk calculations → risk_analyst.
  // Both Workers run in parallel; Lead aggregates and replies.
  const events = await team.stream(
    'Analyze my portfolio: market analyst handles price data, risk analyst handles risk assessment, then give me combined recommendations'
  );

  for await (const event of events) {
    if (event.type === 'text_delta') process.stdout.write(event.text);
    else if (event.type === 'worker_started') console.log(`\n[Team] ${event.workerId} started`);
    else if (event.type === 'worker_completed') console.log(`\n[Team] ${event.workerId} done`);
    else if (event.type === 'end') console.log('\n');
  }
}

buildFinanceTeam().catch(console.error);
```

### 5.5 Full System: All Four Features Working Together

Combine the above into a complete financial research terminal:

```typescript
import { Agent, AgentTeam, SessionLane } from '@a3s-lab/code';
import * as readline from 'readline';

async function main() {
  const agent = await Agent.create('agent.hcl');
  const rl = readline.createInterface({ input: process.stdin, output: process.stdout });
  rl.on('close', () => process.exit(0));

  // Main session: skills loaded, auto-planning enabled
  const session = agent.session('.', {
    tools: financeTools,
    skills: ['portfolio_analyst'],
    role: 'lead',
    queueConfig: { queryMaxConcurrency: 4 },  // up to 4 parallel Query lane tasks
  });

  // Register slash command for parallel research
  session.registerCommand({
    name: 'research',
    description: 'Research multiple stocks in parallel. Usage: /research AAPL MSFT NVDA',
    execute: async (args) => {
      const symbols = args.trim().split(/\s+/).filter(Boolean);
      if (symbols.length === 0) return { text: 'Usage: /research AAPL MSFT NVDA' };

      console.log(`\nLaunching ${symbols.length} parallel research tasks...\n`);
      const tasks = symbols.map((sym) => ({
        prompt: `Analyze ${sym}: quote, risk level, investment recommendation`,
        lane: SessionLane.Generate,
      }));

      const results = await session.submitBatch(tasks);
      return { text: JSON.stringify(results, null, 2) };
    },
  });

  console.log('Financial research system ready.\n');
  console.log('  > Give me a complete portfolio analysis        (auto-planning + skills)');
  console.log('  > /research AAPL MSFT NVDA TSLA               (parallel research)');
  console.log('  > Build a team to deep-dive the tech sector   (Agent Team)\n');

  while (true) {
    const input = await new Promise<string>((resolve) => rl.question('> ', resolve));
    if (!input.trim()) continue;

    if (input.startsWith('/')) {
      const output = await session.executeCommand(input);
      console.log(output.text + '\n');
      continue;
    }

    const events = await session.stream(input);
    for await (const event of events) {
      if (event.type === 'text_delta') process.stdout.write(event.text);
      else if (event.type === 'tool_use') process.stdout.write(`\n→ [${event.tool}] `);
      else if (event.type === 'end') console.log('\n');
    }
  }
}

main().catch(console.error);
```

The fundamental difference between this system and an ordinary chatbot: when the user says "do a full analysis," the system **autonomously plans the steps**, **executes research in parallel**, **coordinates multiple specialized Agents**, and aggregates everything into a structured report — without the user needing to guide each step. That's the core value of an Agentic application.

---

## VII. From Single Machine to Multi-Machine: The Value of Lane Queues

The above builds a single-machine version. When your product needs to handle more complex scenarios — serving multiple users simultaneously, or distributing compute-intensive tasks to remote machines — the lane queue provides the solution.

The lane queue divides tool calls into four priority channels:

```
Control (P0) ← Control instructions, highest priority, sequential execution
Query   (P1) ← Read files, search, parallel execution
Execute (P2) ← Write files, run commands, sequential execution
Generate(P3) ← LLM calls, lowest priority
```

Parallel execution in the Query channel is the key optimization: when the LLM returns multiple file-read requests in a single turn, they execute in parallel rather than waiting serially.

```typescript
import { SessionQueueConfig } from '@a3s-lab/code';

const session = agent.session(process.cwd(), {
  queueConfig: {
    enableAllFeatures: true,
    queryMaxConcurrency: 8,  // up to 8 read operations in parallel
  },
});
```

When you need to dispatch execution tasks to remote machines:

```typescript
// Switch Execute channel to external mode
await session.setLaneHandler('execute', {
  mode: 'external',
  timeoutMs: 120_000,
});

// Listen for external tasks and dispatch to Workers
const events = await session.stream('Run the full test suite and fix all failures');
for await (const event of events) {
  if (event.type === 'external_task_pending') {
    const tasks = await session.pendingExternalTasks();
    for (const task of tasks) {
      // Send to remote Worker (your transport layer: gRPC, HTTP, message queue, etc.)
      const result = await dispatchToWorker(task);
      await session.completeExternalTask(task.task_id, result);
    }
  }
}
```

This pattern lets you transparently distribute compute-intensive tasks to any number of remote machines without modifying Agent logic.

---

## VIII. Conclusion

The core of Agentic AI is the perceive–decide–act loop, and coding tasks are the highest-density test of this loop.

Building reliable Agentic AI systems requires two core principles:

**Minimal core** — the non-replaceable parts of the system should be as small as possible, containing only the components necessary to drive LLM turns.

**Tool bootstrapping** — all extended capabilities are implemented through tools. The LLM is the best tool router. Core code stays unchanged.

On product positioning: Claude Code and OpenCode center on terminal interaction experience, designed for developers. A3S Code centers on embeddability, designed for product builders. This isn't competition — it's division of labor.

If you're **using** a coding Agent, Claude Code is the most mature choice.

If you're **building** a product that includes coding Agent capability, A3S Code provides the infrastructure you need — from a single-machine interactive assistant to a multi-machine distributed execution system, all on the same API.

---

*A3S Code is an open-source Rust coding Agent framework with Rust, Node.js, and Python SDKs. [View Docs](/docs/code) · [GitHub](https://github.com/A3S-Lab/Code)*
