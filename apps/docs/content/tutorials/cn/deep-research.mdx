---
title: æ„å»º DeepResearch æ™ºèƒ½ä½“
description: ä½¿ç”¨ A3S Code æ„å»ºç”Ÿäº§çº§ç ”ç©¶æ™ºèƒ½ä½“ â€” å¤šæœºå™¨å¹¶è¡Œç½‘é¡µæœç´¢ã€å®æ—¶æµå¼åˆæˆã€ç»“æ„åŒ–æŠ¥å‘Šç”Ÿæˆã€‚
full: true
---

import { Step, Steps } from 'fumadocs-ui/components/steps';
import { Callout } from 'fumadocs-ui/components/callout';

æœ¬æ•™ç¨‹å°†å¸¦ä½ æ„å»ºä¸€ä¸ªçœŸæ­£æ„ä¹‰ä¸Šçš„ **DeepResearch** æ™ºèƒ½ä½“ï¼Œè¿œè¶…ç®€å•çš„"æœç´¢+æ€»ç»“"å¾ªç¯ã€‚å®ƒå……åˆ†åˆ©ç”¨ A3S Code çš„æ ¸å¿ƒèƒ½åŠ›å®ç°çœŸæ­£çš„å¹¶è¡Œç ”ç©¶ï¼š

1. å°†é—®é¢˜åˆ†è§£ä¸ºå¤šä¸ªèšç„¦çš„å­æŸ¥è¯¢
2. é€šè¿‡ Lane é˜Ÿåˆ—å°†æ¯ä¸ªæœç´¢ä»»åŠ¡åˆ†å‘åˆ°**å¤–éƒ¨ Worker**ï¼ˆç‹¬ç«‹æœºå™¨/è¿›ç¨‹ï¼‰
3. ç»“æœåˆ°è¾¾æ—¶å®æ—¶æµå¼åˆæˆ
4. ç”Ÿæˆå¸¦å¼•ç”¨çš„ç»“æ„åŒ– Markdown æŠ¥å‘Š

<Callout type="info">
  å…ˆå®‰è£… SDKï¼š`pip install a3s-code`ã€‚åœ¨ `~/.a3s/config.hcl` ä¸­é…ç½®å¥½ LLM æä¾›å•†å¯†é’¥ã€‚
</Callout>

---

## æ¼”ç¤ºæµç¨‹

<ScrollyCoding>
<ScrollySteps>

<ScrollyStep index={0}>

### é¡¹ç›®ç»“æ„

ä¸‰ä¸ªæ–‡ä»¶ï¼š`agent.hcl` æ™ºèƒ½ä½“ + é˜Ÿåˆ— + æœç´¢é…ç½®ï¼Œ`main.py` åè°ƒå™¨ï¼Œ`worker.py` è¿œç¨‹ä»»åŠ¡æ‰§è¡Œå™¨ã€‚

</ScrollyStep>

<ScrollyStep index={1}>

### æ™ºèƒ½ä½“é…ç½®ï¼ˆHCLï¼‰

`agent.hcl` é…ç½®æ¨¡å‹ã€å¯ç”¨ Lane é˜Ÿåˆ—ï¼ˆ`query_max_concurrency = 8`ï¼‰ä»¥åŠå†…ç½®å¤šå¼•æ“æœç´¢ï¼ˆGoogleã€Bingã€DuckDuckGoï¼‰ã€‚

</ScrollyStep>

<ScrollyStep index={2}>

### åˆ›å»ºæ™ºèƒ½ä½“å’Œä¼šè¯

`Agent.create()` åŠ è½½é…ç½®ã€‚`SessionQueueConfig` åœ¨ä»£ç ä¸­é•œåƒ HCL é˜Ÿåˆ—è®¾ç½®ã€‚`set_lane_handler("execute", mode="external")` å°†æ‰€æœ‰ `bash`/`write` å·¥å…·è°ƒç”¨è·¯ç”±åˆ°å¤–éƒ¨ Workerï¼Œè€Œéæœ¬åœ°æ‰§è¡Œã€‚

</ScrollyStep>

<ScrollyStep index={3}>

### åˆ†è§£é—®é¢˜

å‘æ™ºèƒ½ä½“å‘é€è§„åˆ’æç¤ºï¼Œè¿”å› JSON æ ¼å¼çš„å­æŸ¥è¯¢æ•°ç»„ã€‚å¹¶è¡Œé˜¶æ®µå¼€å§‹å‰å…ˆè§£æè¿™äº›å­æŸ¥è¯¢â€”â€”è§£æå¤±è´¥åˆ™å›é€€åˆ°åŸå§‹é—®é¢˜ã€‚

</ScrollyStep>

<ScrollyStep index={4}>

### è·¨ Worker å¹¶è¡Œæœç´¢

ç”¨ `asyncio.to_thread` + `asyncio.gather` å¹¶å‘è¿è¡Œæ‰€æœ‰å­æŸ¥è¯¢ã€‚æ¯ä¸ªä»»åŠ¡ç›´æ¥è°ƒç”¨ `session.tool("web_search", ...)` â€” æ— éœ€ LLM å¾€è¿”ã€‚Lane é˜Ÿåˆ—å°†å¹¶å‘æ•°é™åˆ¶åœ¨ 8ã€‚

</ScrollyStep>

<ScrollyStep index={5}>

### å¤–éƒ¨ä»»åŠ¡å¤„ç†å™¨

åå°çº¿ç¨‹è½®è¯¢ `session.pending_external_tasks()`ã€‚å½“æ™ºèƒ½ä½“è§¦å‘ `bash`/`write` ä»»åŠ¡æ—¶ï¼Œè½®è¯¢å™¨æ¥æ”¶ä»»åŠ¡ã€å‘é€åˆ°è¿œç¨‹ Workerï¼Œå†è°ƒç”¨ `session.complete_external_task()` æ¢å¤æ™ºèƒ½ä½“ã€‚ç”Ÿäº§ç¯å¢ƒä¸­å°† `worker.execute()` æ›¿æ¢ä¸º gRPC / SSH / æ¶ˆæ¯é˜Ÿåˆ—ã€‚

</ScrollyStep>

<ScrollyStep index={6}>

### æµå¼åˆæˆ

å°†æ‰€æœ‰æœç´¢ç»“æœä¼ å›æ™ºèƒ½ä½“ã€‚éå† `session.stream()` â€” `text_delta` äº‹ä»¶å®æ—¶æ‰“å°è¾“å‡ºï¼Œ`tool_start`/`tool_end` æ˜¾ç¤ºå·¥å…·æ´»åŠ¨ï¼Œ`end` æºå¸¦æœ€ç»ˆ Token ç”¨é‡ã€‚

</ScrollyStep>

<ScrollyStep index={7}>

### å®Œæ•´åè°ƒå™¨

å®Œæ•´çš„ `main.py`ã€‚è¿è¡Œæ–¹å¼ï¼š

```bash
python main.py "æœºå¯†è®¡ç®—é¢†åŸŸçš„æœ€æ–°è¿›å±•"
```

</ScrollyStep>

</ScrollySteps>

<ScrollyCode>

```text é¡¹ç›®ç»“æ„
deep-research/
â”œâ”€â”€ agent.hcl   # æ™ºèƒ½ä½“ + é˜Ÿåˆ— + æœç´¢é…ç½®
â”œâ”€â”€ main.py     # åè°ƒå™¨ï¼šè§„åˆ’ â†’ å¹¶è¡Œæœç´¢ â†’ åˆæˆ
â””â”€â”€ worker.py   # è¿œç¨‹ Workerï¼šæ‰§è¡Œ ExternalTask
```

```hcl æ™ºèƒ½ä½“é…ç½®
# agent.hcl
default_model = "anthropic/claude-sonnet-4-20250514"

providers {
  name    = "anthropic"
  api_key = env("ANTHROPIC_API_KEY")
}

# Lane é˜Ÿåˆ— â€” æ§åˆ¶å¹¶è¡Œæ‰§è¡Œ
queue {
  query_max_concurrency   = 8   # æœ€å¤š 8 ä¸ªå¹¶è¡Œæœç´¢
  execute_max_concurrency = 4
  enable_metrics          = true
  enable_dlq              = true

  retry_policy {
    strategy         = "exponential"
    max_retries      = 3
    initial_delay_ms = 200
  }
}

# å†…ç½®å¤šå¼•æ“æœç´¢
search {
  timeout = 30

  engine {
    google     { enabled = true; weight = 1.5 }
    bing       { enabled = true; weight = 1.0 }
    duckduckgo { enabled = true; weight = 1.2 }
  }
}
```

```python åˆ›å»ºæ™ºèƒ½ä½“å’Œä¼šè¯
# main.py
import asyncio
import threading
import sys
import json
from a3s_code import Agent, SessionQueueConfig
import worker

def create_session(config_path):
    agent = Agent.create(config_path)

    # ä¸ HCL é˜Ÿåˆ—é…ç½®ä¿æŒä¸€è‡´
    qc = SessionQueueConfig()
    qc.set_query_concurrency(8)
    qc.set_execute_concurrency(4)
    qc.enable_metrics()
    qc.enable_dlq()

    session = agent.session(".", queue_config=qc, permissive=True)

    # å°† Execute é€šé“è·¯ç”±åˆ°å¤–éƒ¨ Worker
    session.set_lane_handler(
        "execute", mode="external", timeout_ms=60_000
    )
    return session
```

```python åˆ†è§£é—®é¢˜
def plan_sub_queries(session, question):
    result = session.send(
        f"å°†ä»¥ä¸‹ç ”ç©¶é—®é¢˜æ‹†è§£ä¸º 5-8 ä¸ªèšç„¦çš„å­æŸ¥è¯¢ï¼Œ"
        f"ç”¨äºå¹¶è¡Œç½‘é¡µæœç´¢ã€‚åªè¿”å› JSON å­—ç¬¦ä¸²æ•°ç»„ã€‚\n\n"
        f"é—®é¢˜ï¼š{question}"
    )
    try:
        sub_queries = json.loads(result.text)
        if isinstance(sub_queries, list):
            return sub_queries
    except json.JSONDecodeError:
        pass
    # è§£æå¤±è´¥æ—¶å›é€€åˆ°åŸå§‹é—®é¢˜
    return [question]
```

```python è·¨ Worker å¹¶è¡Œæœç´¢
async def parallel_search(session, sub_queries):
    print(f"ğŸ“‹ å·²è§„åˆ’ {len(sub_queries)} ä¸ªå­æŸ¥è¯¢")

    async def search_one(query):
        print(f"  ğŸ” æœç´¢ä¸­ï¼š{query}")
        result = await asyncio.to_thread(
            session.tool,
            "web_search",
            {
                "query":   query,
                "engines": "google,bing,ddg",
                "limit":   8,
                "timeout": 20,
                "format":  "text",
            },
        )
        return result.output if result.exit_code == 0 else ""

    results = await asyncio.gather(
        *[search_one(q) for q in sub_queries],
        return_exceptions=True,
    )

    # è¿‡æ»¤æ‰é”™è¯¯ç»“æœ
    return [r for r in results if isinstance(r, str) and r]
```

```python å¤–éƒ¨ä»»åŠ¡å¤„ç†å™¨
def start_external_worker(session, stop_event):
    """åå°çº¿ç¨‹ï¼šè½®è¯¢å¹¶åˆ†å‘ ExternalTaskã€‚"""
    def poll():
        while not stop_event.is_set():
            try:
                tasks = session.pending_external_tasks()
                for task in tasks:
                    tid  = task["task_id"]
                    kind = task["command_type"]
                    print(f"  ğŸ“¥ å¤–éƒ¨ä»»åŠ¡ï¼š{tid[:8]} ({kind})")

                    # --- åœ¨æ­¤å¤„è½¬å‘åˆ°è¿œç¨‹ Worker ---
                    out = worker.execute(task)

                    session.complete_external_task(
                        tid,
                        success=out["success"],
                        result={
                            "output":    out["output"],
                            "exit_code": out["exit_code"],
                        },
                        error=out.get("error"),
                    )
                    print(f"  ğŸ“¤ ä»»åŠ¡ {tid[:8]} å·²å®Œæˆ")
            except Exception:
                pass
            stop_event.wait(timeout=0.2)

    t = threading.Thread(target=poll, daemon=True)
    t.start()
    return t
```

```python æµå¼åˆæˆ
async def synthesize(session, question, results):
    context = "\n\n---\n\n".join(results)
    prompt = (
        f"ä½ æ˜¯ä¸€ä½ç ”ç©¶åˆ†æå¸ˆã€‚æ ¹æ®ä»¥ä¸‹æœç´¢ç»“æœï¼Œ"
        f"æ’°å†™å…³äº"{question}"çš„å®Œæ•´ Markdown æŠ¥å‘Šã€‚\n\n"
        f"è¦æ±‚ï¼š\n"
        f"- æ¯ä¸ªå­ä¸»é¢˜ä½¿ç”¨æ¸…æ™°çš„ ## æ ‡é¢˜\n"
        f"- é¡¶éƒ¨åˆ—å‡º"æ ¸å¿ƒå‘ç°"è¦ç‚¹\n"
        f"- ä½¿ç”¨ [æ ‡é¢˜](url) æ ¼å¼å†…è”å¼•ç”¨\n"
        f"- æ˜ç¡®æ ‡æ³¨çŸ›ç›¾è§‚ç‚¹\n"
        f"- æœ«å°¾é™„"å‚è€ƒæ¥æº"ç« èŠ‚\n\n"
        f"æœç´¢ç»“æœï¼š\n{context}"
    )

    print("\n# ç ”ç©¶æŠ¥å‘Š\n")

    for event in session.stream(prompt):
        if event.event_type == "text_delta":
            print(event.text, end="", flush=True)
        elif event.event_type == "tool_start":
            print(f"\n  ğŸ”§ å·¥å…·ï¼š{event.tool_name}", flush=True)
        elif event.event_type == "end":
            print(f"\n\n---\nâœ“ å…±æ¶ˆè€— {event.total_tokens} tokens")
            break
        elif event.event_type == "error":
            print(f"\nâŒ {event.error}")
            break
```

```python å®Œæ•´åè°ƒå™¨
# main.py â€” å®Œæ•´æ–‡ä»¶
import asyncio
import threading
import sys
import json
from pathlib import Path
from a3s_code import Agent, SessionQueueConfig
import worker


def find_config():
    p = Path.home() / ".a3s" / "config.hcl"
    if p.exists():
        return str(p)
    raise FileNotFoundError("~/.a3s/config.hcl æœªæ‰¾åˆ°")


async def main():
    question = (
        sys.argv[1] if len(sys.argv) > 1
        else "æœºå¯†è®¡ç®—é¢†åŸŸçš„æœ€æ–°è¿›å±•"
    )

    agent = Agent.create(find_config())

    qc = SessionQueueConfig()
    qc.set_query_concurrency(8)
    qc.set_execute_concurrency(4)
    qc.enable_metrics()
    qc.enable_dlq()

    session = agent.session(".", queue_config=qc, permissive=True)
    session.set_lane_handler("execute", mode="external", timeout_ms=60_000)

    # å¯åŠ¨å¤–éƒ¨ä»»åŠ¡è½®è¯¢å™¨
    stop = threading.Event()
    start_external_worker(session, stop)

    # è§„åˆ’
    result = session.send(
        f"æ‹†è§£ä¸º 5-8 ä¸ªå­æŸ¥è¯¢ç”¨äºå¹¶è¡Œæœç´¢ï¼Œ"
        f"åªè¿”å› JSON æ•°ç»„ã€‚\n\né—®é¢˜ï¼š{question}"
    )
    try:
        sub_queries = json.loads(result.text)
    except Exception:
        sub_queries = [question]

    # å¹¶è¡Œæœç´¢
    async def search_one(query):
        r = await asyncio.to_thread(
            session.tool, "web_search",
            {"query": query, "engines": "google,bing,ddg",
             "limit": 8, "timeout": 20, "format": "text"},
        )
        return r.output if r.exit_code == 0 else ""

    raw = await asyncio.gather(*[search_one(q) for q in sub_queries])
    results = [r for r in raw if r]
    print(f"âœ“ {len(results)} ä¸ªæœç´¢å·²å®Œæˆ")

    # åˆæˆ
    context = "\n\n---\n\n".join(results)
    for event in session.stream(
        f"æ’°å†™å…³äº"{question}"çš„å®Œæ•´ Markdown æŠ¥å‘Šã€‚\n\n"
        f"ä½¿ç”¨ ## æ ‡é¢˜ã€å†…è”å¼•ç”¨ã€é¡¶éƒ¨æ ¸å¿ƒå‘ç°ã€"
        f"æœ«å°¾å‚è€ƒæ¥æºã€‚\n\næœç´¢ç»“æœï¼š\n{context}"
    ):
        if event.event_type == "text_delta":
            print(event.text, end="", flush=True)
        elif event.event_type == "end":
            print(f"\nâœ“ {event.total_tokens} tokens")
            break
        elif event.event_type == "error":
            print(f"\nâŒ {event.error}")
            break

    stop.set()


if __name__ == "__main__":
    asyncio.run(main())
```

</ScrollyCode>
</ScrollyCoding>

---

## è¿›é˜¶æ‰©å±•

<Steps>
<Step>

### åŠ¨æ€åˆ‡æ¢ Worker æ¨¡å¼

è¿è¡Œæ—¶éšæ—¶åˆ‡æ¢é€šé“å¤„ç†å™¨ â€” `internal` æœ¬åœ°æ‰§è¡Œã€`external` è¿œç¨‹æ‰§è¡Œã€`hybrid` åŒæ—¶æ‰§è¡Œå¹¶é€šçŸ¥å¤–éƒ¨ç³»ç»Ÿï¼š

```python
# åˆ‡æ¢åˆ°æ··åˆæ¨¡å¼ï¼šæœ¬åœ°æ‰§è¡Œ + é€šçŸ¥å¤–éƒ¨ç³»ç»Ÿ
session.set_lane_handler("execute", mode="hybrid", timeout_ms=30_000)
```

</Step>
<Step>

### ç›‘æ§é˜Ÿåˆ—å‹åŠ›

ç”¨é˜Ÿåˆ—æŒ‡æ ‡åœ¨ç§¯å‹æ—¶è‡ªåŠ¨æ‰©ç¼© Workerï¼š

```python
if session.has_queue():
    stats = session.queue_stats()
    print(f"ç­‰å¾…ä¸­ï¼š{stats['total_pending']}")
    print(f"æ‰§è¡Œä¸­ï¼š{stats['total_active']}")
    print(f"å¤±è´¥æ•°ï¼š{stats['total_failed']}")
    print(f"DLQï¼š  {stats['dlq_size']}")
```

</Step>
<Step>

### å¯ç”¨è§„åˆ’å’Œç›®æ ‡è¿½è¸ª

å¼€å¯å†…ç½®è§„åˆ’å™¨ï¼Œè®©æ™ºèƒ½ä½“åœ¨æœç´¢å‰è‡ªåŠ¨åˆ†è§£ç ”ç©¶ä»»åŠ¡ï¼š

```python
session = agent.session(
    ".",
    queue_config=qc,
    planning=True,
    goal_tracking=True,
    permissive=True,
)
```

</Step>
</Steps>
