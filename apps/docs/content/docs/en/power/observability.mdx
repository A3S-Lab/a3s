---
title: Observability
description: Prometheus metrics, health endpoint, and audit logging
---

import { TypeTable } from 'fumadocs-ui/components/type-table';

# Observability

## Health Endpoint

`GET /health` — returns server status, TEE state, and loaded model count.

```bash
curl http://localhost:11434/health
```

```json
{
  "status": "ok",
  "version": "0.2.0",
  "uptime_seconds": 3600,
  "loaded_models": 2,
  "tee": {
    "enabled": true,
    "type": "sev-snp",
    "models_verified": true
  }
}
```

## Prometheus Metrics

`GET /metrics` — returns metrics in Prometheus text format.

```bash
curl http://localhost:11434/metrics
```

### Request Metrics

<TypeTable
  type={{
    "power_requests_total": { description: "Total requests by method, path, and status code" },
    "power_request_duration_seconds": { description: "Request duration histogram" },
    "power_concurrent_requests": { description: "Current number of in-flight requests" },
  }}
/>

### Inference Metrics

<TypeTable
  type={{
    "power_inference_tokens_total": { description: "Total tokens generated by model" },
    "power_inference_prompt_tokens_total": { description: "Total prompt tokens processed" },
    "power_inference_duration_seconds": { description: "Inference duration histogram" },
    "power_ttft_seconds": { description: "Time to first token histogram" },
  }}
/>

### Model Metrics

<TypeTable
  type={{
    "power_models_loaded": { description: "Number of currently loaded models" },
    "power_model_memory_bytes": { description: "Estimated memory usage per loaded model" },
    "power_model_load_duration_seconds": { description: "Model load time histogram" },
  }}
/>

### GPU Metrics

<TypeTable
  type={{
    "power_gpu_utilization_percent": { description: "GPU utilization percentage" },
    "power_gpu_memory_used_bytes": { description: "GPU memory used" },
    "power_gpu_memory_total_bytes": { description: "GPU memory total" },
  }}
/>

### TEE Metrics

<TypeTable
  type={{
    "power_tee_attestations_total": { description: "Total attestation reports generated" },
    "power_tee_model_decryptions_total": { description: "Total encrypted model decryptions" },
    "power_tee_redactions_total": { description: "Total log redactions applied" },
  }}
/>

## Prometheus Scrape Config

```yaml
scrape_configs:
  - job_name: a3s-power
    static_configs:
      - targets: ["localhost:11434"]
    metrics_path: /metrics
```

## Audit Logging

Power writes structured audit logs in JSONL format. Each inference request is logged with timing, model name, token counts (optionally rounded), and request ID — but never with prompt or response content when `redact_logs = true`.

Audit logs are flushed on graceful shutdown (SIGTERM / Ctrl-C) before the process exits.

## Logging

Power uses `tracing` with `tracing-subscriber`. Set log level via `RUST_LOG`:

```bash
RUST_LOG=info a3s-power serve
RUST_LOG=debug a3s-power serve
RUST_LOG=a3s_power=debug,tower_http=info a3s-power serve
```

When `redact_logs = true`, all inference content is stripped from log output regardless of log level.
