---
title: CLI Reference
description: Complete command reference for a3s-power
---

import { TypeTable } from 'fumadocs-ui/components/type-table';

# CLI Reference

A3S Power provides 12 commands for model management, inference, and server operations.

## Global Options

```bash
a3s-power [OPTIONS] <COMMAND>

Options:
  -h, --help     Print help
  -V, --version  Print version
```

## Model Management

### pull

Download a model from a registry.

```bash
a3s-power pull <MODEL>

# Examples
a3s-power pull llama3.2
a3s-power pull qwen2.5:7b
a3s-power pull hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF
a3s-power pull --insecure my-registry.local/model
```

<TypeTable
  type={{
    "--insecure": {
      description: "Skip TLS verification",
    },
  }}
/>

### list

List all local models.

```bash
a3s-power list
```

Output:

```
NAME              SIZE      FORMAT    QUANTIZATION  MODIFIED
llama3.2          2.0 GB    gguf      Q4_K_M        2 hours ago
qwen2.5:7b        4.7 GB    gguf      Q4_K_M        1 day ago
```

### show

Show model details.

```bash
a3s-power show <MODEL> [OPTIONS]

# Examples
a3s-power show llama3.2
a3s-power show llama3.2 --verbose
```

<TypeTable
  type={{
    "--verbose": {
      description: "Show full GGUF metadata",
    },
  }}
/>

### delete

Delete a local model.

```bash
a3s-power delete <MODEL>

# Example
a3s-power delete llama3.2
```

### cp

Copy or alias a model.

```bash
a3s-power cp <SOURCE> <DESTINATION>

# Example
a3s-power cp llama3.2 my-llama
```

### create

Create a model from a Modelfile.

```bash
a3s-power create <NAME> -f <MODELFILE>

# Example
a3s-power create my-model -f Modelfile
```

### push

Push a model to a remote registry.

```bash
a3s-power push <MODEL> --destination <URL>

# Example
a3s-power push my-model --destination https://registry.example.com
```

<TypeTable
  type={{
    "--destination": {
      description: "Remote registry URL",
    },
    "--insecure": {
      description: "Skip TLS verification",
    },
  }}
/>

## Inference

### run

Interactive chat or single prompt execution.

```bash
a3s-power run <MODEL> [OPTIONS] [PROMPT]

# Interactive chat
a3s-power run llama3.2

# Single prompt
a3s-power run llama3.2 "Explain quicksort"

# With options
a3s-power run llama3.2 --temperature 0.7 --num-predict 256 "Write a haiku"
```

<TypeTable
  type={{
    "--temperature": {
      description: "Default: 0.8 · Description: Sampling temperature",
    },
    "--top-p": {
      description: "Default: 0.9 · Description: Nucleus sampling",
    },
    "--top-k": {
      description: "Default: 40 · Description: Top-K sampling",
    },
    "--num-predict": {
      description: "Default: -1 · Description: Max tokens to generate",
    },
    "--num-ctx": {
      description: "Default: 2048 · Description: Context window size",
    },
    "--repeat-penalty": {
      description: "Default: 1.1 · Description: Repetition penalty",
    },
    "--seed": {
      description: "Description: Random seed",
    },
    "--format": {
      description: {`Description: Output format (\`json\`)`},
    },
    "--system": {
      description: "Description: Override system prompt",
    },
    "--template": {
      description: "Description: Override chat template",
    },
    "--keep-alive": {
      description: {`Default: \`5m\` · Description: Model keep-alive duration`},
    },
    "--verbose": {
      description: "Description: Show timing and token stats",
    },
    "--insecure": {
      description: "Description: Skip TLS verification",
    },
  }}
/>

In interactive mode, type your messages and press Enter. Use `/bye` or Ctrl+C to exit.

## Server

### serve

Start the HTTP server.

```bash
a3s-power serve [OPTIONS]

# Default (127.0.0.1:11434)
a3s-power serve

# Custom bind
a3s-power serve --host 0.0.0.0 --port 8080
```

<TypeTable
  type={{
    "--host": {
      description: {`Default: \`127.0.0.1\` · Description: Bind address`},
    },
    "--port": {
      description: {`Default: \`11434\` · Description: Bind port`},
    },
  }}
/>

### ps

List currently loaded/running models.

```bash
a3s-power ps
```

Output:

```
NAME          SIZE      VRAM       UNTIL
llama3.2      2.0 GB    1.8 GB     4 minutes from now
```

### stop

Stop/unload a running model.

```bash
a3s-power stop <MODEL>

# Example
a3s-power stop llama3.2
```

## Environment Variables

All CLI behavior can be configured via environment variables. See [Configuration](./configuration) for the full list.

```bash
# Common overrides
OLLAMA_HOST=0.0.0.0:8080 a3s-power serve
OLLAMA_KEEP_ALIVE=1h a3s-power run llama3.2
OLLAMA_NUM_GPU=0 a3s-power run llama3.2  # CPU only
```
