---
title: Context Management
description: Context compaction and pluggable context providers for RAG
---

# Context Management

A3S Code provides two context management features: **automatic context compaction** when conversations grow long, and **pluggable context providers** for retrieval-augmented generation (RAG).

import { Steps, Step } from 'fumadocs-ui/components/steps';
import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

## Context Compaction

When context usage exceeds the threshold (default 80% of model's context window), the agent automatically summarizes the conversation to stay within limits.

### How It Works

<Steps>
<Step>Keep first 2 messages (system context)</Step>
<Step>Keep last 20 messages (recent context)</Step>
<Step>Summarize middle messages via LLM call</Step>
<Step>Insert summary as a synthetic message</Step>
</Steps>

This preserves important context while reducing token usage.

### Configuration

```rust
use a3s_code_core::SessionOptions;

let session = agent.session("/project", Some(
    SessionOptions::new()
        .with_context_threshold(0.8)  // Compact at 80% (default)
))?;
```

### Events

The agent emits events during compaction:

| Event | When |
|-------|------|
| `ContextWarning` | Context usage exceeds threshold |
| `ContextCompacting` | Compaction started |
| `ContextCompacted` | Compaction completed |

## Context Providers

Context providers inject additional information into the LLM's system prompt before each generation. This enables RAG (retrieval-augmented generation), memory recall, and integration with external knowledge bases.

### Overview

The agent queries registered context providers before each LLM call. Providers return `ContextItem` entries that are formatted as XML blocks and prepended to the system prompt:

```
System Prompt
├── Base instructions
├── Context blocks:          ← injected by context providers
│   ├── [resource] API docs for auth module
│   ├── [memory] User prefers TypeScript
│   └── [resource] Related code snippets
└── Tool definitions
```

Events are emitted during resolution: `ContextResolving` (with provider names) and `ContextResolved` (with total items and token count).

### ContextProvider Trait

```rust
#[async_trait]
pub trait ContextProvider: Send + Sync {
    /// Query this provider for relevant context
    async fn query(&self, query: ContextQuery) -> Result<ContextResult>;

    /// Optional: extract and store context after a turn completes
    async fn on_turn_complete(&self, _messages: &[Message]) -> Result<()> {
        Ok(()) // default no-op
    }
}
```

The `query()` method receives a `ContextQuery` and returns matching `ContextItem` entries. The optional `on_turn_complete()` hook allows providers to extract and store information from conversation turns (e.g., memory extraction).

### ContextQuery

<TypeTable
  type={{
    query: {
      type: 'String',
      required: true,
      description: 'The search query (usually the user\'s prompt)',
    },
    context_types: {
      type: 'Vec<ContextType>',
      description: 'Types to retrieve',
    },
    depth: {
      type: 'ContextDepth',
      description: 'How much detail to return',
    },
    max_results: {
      type: 'usize',
      description: 'Maximum items to return',
    },
    max_tokens: {
      type: 'usize',
      description: 'Token budget for results',
    },
    session_id: {
      type: 'Option<String>',
      description: 'Scope results to a session',
    },
    params: {
      type: 'HashMap<String, String>',
      description: 'Provider-specific parameters',
    },
  }}
/>

Builder methods make construction ergonomic:

```rust
let query = ContextQuery::new("authentication flow")
    .with_types(vec![ContextType::Resource])
    .with_depth(ContextDepth::Overview)
    .with_max_results(5)
    .with_max_tokens(4000)
    .with_session_id("session-123");
```

#### ContextType

| Type | Description |
|------|-------------|
| `Memory` | Memory items (episodic, semantic, procedural, working) |
| `Resource` | External resources (files, docs, code) — default |

#### ContextDepth

| Depth | Token Budget | Description |
|-------|-------------|-------------|
| `Abstract` | ~100 tokens | Brief summary |
| `Overview` | ~2,000 tokens | Moderate detail (default) |
| `Full` | Variable | Complete content |

### ContextItem

<TypeTable
  type={{
    id: {
      type: 'String',
      description: 'Unique item identifier',
    },
    context_type: {
      type: 'ContextType',
      description: 'Memory or Resource',
    },
    content: {
      type: 'String',
      description: 'The context content',
    },
    token_count: {
      type: 'usize',
      description: 'Estimated token count',
    },
    relevance: {
      type: 'f32',
      description: '0.0–1.0 relevance score',
    },
    source: {
      type: 'Option<String>',
      description: 'Where this context came from',
    },
    metadata: {
      type: 'HashMap<String, String>',
      description: 'Additional metadata',
    },
  }}
/>

Items are formatted as XML for injection into the system prompt via `to_xml()`.

## Built-in Provider: MemoryContextProvider

Bridges the [Memory](/docs/code/memory) system to the context provider interface. Performs semantic search over memory items and converts them to `ContextItem` entries with relevance scores.

```rust
use a3s_code_core::context::MemoryContextProvider;
use a3s_code_core::memory::MemoryManager;

let memory = Arc::new(MemoryManager::new());
let provider = Arc::new(MemoryContextProvider::new(memory));

let session = agent.session("/project", Some(
    SessionOptions::new().with_context_provider(provider)
))?;
```

## Custom Context Provider Example

```rust
use a3s_code_core::context::{ContextProvider, ContextQuery, ContextResult, ContextItem, ContextType};
use async_trait::async_trait;

struct DocsContextProvider {
    docs_path: PathBuf,
}

#[async_trait]
impl ContextProvider for DocsContextProvider {
    async fn query(&self, query: ContextQuery) -> Result<ContextResult> {
        // Search documentation files
        let matches = search_docs(&self.docs_path, &query.query)?;

        let items: Vec<ContextItem> = matches.into_iter()
            .map(|doc| ContextItem {
                id: doc.path.to_string_lossy().to_string(),
                context_type: ContextType::Resource,
                content: doc.content,
                token_count: doc.content.split_whitespace().count(),
                relevance: doc.score,
                source: Some(format!("docs:{}", doc.path.display())),
                metadata: HashMap::new(),
            })
            .collect();

        Ok(ContextResult { items })
    }
}

// Register with session
let provider = Arc::new(DocsContextProvider {
    docs_path: PathBuf::from("./docs"),
});

let session = agent.session("/project", Some(
    SessionOptions::new().with_context_provider(provider)
))?;
```

## Multiple Providers

Register multiple context providers to combine different sources:

```rust
let memory_provider = Arc::new(MemoryContextProvider::new(memory));
let docs_provider = Arc::new(DocsContextProvider { docs_path });
let code_provider = Arc::new(CodeContextProvider { repo_path });

let session = agent.session("/project", Some(
    SessionOptions::new()
        .with_context_provider(memory_provider)
        .with_context_provider(docs_provider)
        .with_context_provider(code_provider)
))?;
```

All providers are queried in parallel, and results are merged before injection into the system prompt.

## Best Practices

<Steps>
<Step>**Set token budgets** — Use `max_tokens` to prevent context overflow</Step>
<Step>**Filter by type** — Use `context_types` to retrieve only relevant context</Step>
<Step>**Adjust depth** — Use `Abstract` for summaries, `Full` for detailed content</Step>
<Step>**Implement relevance scoring** — Return items sorted by relevance (0.0–1.0)</Step>
<Step>**Use on_turn_complete** — Extract and store information from conversations</Step>
<Step>**Cache results** — Implement caching in your provider to reduce latency</Step>
</Steps>

## Events

Context-related events emitted during streaming:

| Event | When |
|-------|------|
| `ContextResolving` | Context providers queried |
| `ContextResolved` | Context items retrieved |
| `ContextWarning` | Context usage exceeds threshold |
| `ContextCompacting` | Compaction started |
| `ContextCompacted` | Compaction completed |

See [Sessions](/docs/code/sessions) for full event reference.

## API Reference

### SessionOptions

<TypeTable
  type={{
    fs_context: {
      type: 'Option<string>',
      default: 'None',
      description: 'Filesystem context path. Rust: `.with_fs_context(path)`, TS: `fsContext: path`, Python: `fs_context=path`',
    },
    context_provider: {
      type: 'Option<Arc<dyn ContextProvider>>',
      default: 'None',
      description: 'Custom context provider. Rust: `.with_context_provider(Arc::new(p))`',
    },
    context_threshold: {
      type: 'f32',
      default: '0.8',
      description: 'Context usage fraction to trigger compaction. Rust: `.with_context_threshold(f)`, TS: `contextThreshold: f`, Python: `context_threshold=f`',
    },
  }}
/>

### ContextQuery fields

<TypeTable
  type={{
    query: {
      type: 'String',
      description: 'Natural language query',
    },
    max_tokens: {
      type: 'Option<usize>',
      description: 'Token budget for results',
    },
    context_types: {
      type: 'Vec<ContextType>',
      description: 'Filter by type',
    },
    depth: {
      type: 'ContextDepth',
      description: '`Abstract` or `Full`',
    },
  }}
/>

### ContextItem fields

<TypeTable
  type={{
    content: {
      type: 'String',
      description: 'Context text',
    },
    source: {
      type: 'String',
      description: 'Origin (file path, memory ID, etc.)',
    },
    relevance: {
      type: 'f32',
      description: 'Relevance score (0.0–1.0)',
    },
    context_type: {
      type: 'ContextType',
      description: '`File`, `Memory`, `Skill`, `Custom`',
    },
  }}
/>

### VectorContextConfig (Rust)

<TypeTable
  type={{
    path: {
      type: 'PathBuf',
      required: true,
      description: 'Workspace root. Use `VectorContextConfig::new(path)`',
    },
    min_relevance: {
      type: 'f32',
      default: '0.3',
      description: 'Minimum cosine similarity. Use `.with_min_relevance(f)`',
    },
    max_results: {
      type: 'usize',
      default: '10',
      description: 'Max chunks per query. Use `.with_max_results(n)`',
    },
    chunk_size: {
      type: 'usize',
      default: '1500',
      description: 'Max chars per chunk. Use `.with_chunk_size(n)`',
    },
  }}
/>
