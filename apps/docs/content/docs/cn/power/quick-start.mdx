---
title: 快速开始
description: 几分钟内启动本地模型推理
---

# 快速开始

## 安装

```bash
# 通过 Homebrew
brew install a3s-lab/tap/a3s-power

# 或从源码构建
cargo install a3s-power
```

## 拉取模型

```bash
# 从 Ollama 注册表拉取
a3s-power pull llama3.2

# 拉取指定大小
a3s-power pull qwen2.5:7b

# 从 HuggingFace 拉取（GGUF）
a3s-power pull hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF
```

## 交互式对话

```bash
# 启动交互式对话
a3s-power run llama3.2

# 单次提问
a3s-power run llama3.2 "用三句话解释快速排序"

# 带参数
a3s-power run llama3.2 --temperature 0.7 --num-predict 256 "写一首俳句"
```

## 启动服务器

```bash
# 在默认端口（11434）启动
a3s-power serve

# 自定义地址和端口
a3s-power serve --host 0.0.0.0 --port 8080
```

## 使用 API

Ollama 兼容接口：

```bash
# 对话补全
curl http://localhost:11434/api/chat -d '{
  "model": "llama3.2",
  "messages": [{"role": "user", "content": "你好！"}]
}'

# 列出模型
curl http://localhost:11434/api/tags
```

OpenAI 兼容接口（适用于任何 OpenAI SDK）：

```bash
# 对话补全
curl http://localhost:11434/v1/chat/completions -d '{
  "model": "llama3.2",
  "messages": [{"role": "user", "content": "你好！"}]
}'
```

```python
from openai import OpenAI

client = OpenAI(base_url="http://localhost:11434/v1", api_key="unused")
response = client.chat.completions.create(
    model="llama3.2",
    messages=[{"role": "user", "content": "你好！"}]
)
print(response.choices[0].message.content)
```

## 模型管理

```bash
# 列出本地模型
a3s-power list

# 查看模型详情
a3s-power show llama3.2

# 删除模型
a3s-power delete llama3.2

# 复制/别名
a3s-power cp llama3.2 my-model

# 列出运行中的模型
a3s-power ps

# 停止运行中的模型
a3s-power stop llama3.2
```
