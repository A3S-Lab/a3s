---
title: Architecture
description: System architecture, data flow, and design decisions
---

# Architecture

## Library-First Design

A3S Code is a library-first framework. The core (`a3s-code-core`) embeds directly in your application via native bindings — no server, no IPC overhead.

```
Your Application (Rust / TypeScript / Python)
    │
    ▼ Agent::new("agent.hcl") / Agent.create("agent.hcl")
┌──────────────────────────────────────────────────────┐
│  Agent (config-driven, workspace-independent)         │
│  ┌────────────┬──────────────┬─────────────────────┐ │
│  │ LlmClient  │  CodeConfig  │   SessionManager    │ │
│  └────────────┴──────────────┴─────────────────────┘ │
│                       │                               │
│        agent.session("/workspace", options?)           │
│                       ▼                               │
│  ┌──────────────────────────────────────────────┐    │
│  │  AgentSession (workspace-bound)               │    │
│  │  ┌─────────┬──────────┬──────────┬─────────┐ │    │
│  │  │ Agent   │ Tool     │Permission│  LLM    │ │    │
│  │  │ Loop    │ Executor │ System   │ Provider│ │    │
│  │  │         │ (14)     │          │         │ │    │
│  │  ├─────────┼──────────┼──────────┼─────────┤ │    │
│  │  │ Skills  │ Subagent │  Hook    │  MCP    │ │    │
│  │  │         │          │  Engine  │         │ │    │
│  │  ├─────────┼──────────┼──────────┼─────────┤ │    │
│  │  │ Llm     │ Security │ Memory   │ File    │ │    │
│  │  │ Planner │          │          │ History │ │    │
│  │  ├─────────┼──────────┼──────────┼─────────┤ │    │
│  │  │ Wave    │ Context  │ Cost     │ Cron    │ │    │
│  │  │Scheduler│Compactor │ Tracking │Scheduler│ │    │
│  │  └─────────┴──────────┴──────────┴─────────┘ │    │
│  └──────────────────────────────────────────────┘    │
└──────────────────────────────────────────────────────┘
```

Native bindings:

| Language | Package | Binding |
|----------|---------|---------|
| Rust | `a3s-code-core` | Native |
| Python | `a3s-code` | PyO3 |
| Node.js | `@a3s-lab/code` | napi-rs |

## Core Concepts

| Concept | Description |
|---------|-------------|
| **Agent** | Config-driven top-level object. Holds LLM client and config. Workspace-independent. |
| **AgentSession** | Bound to a specific workspace. All LLM interaction and tool execution happens here. |
| **SessionOptions** | Optional per-session override: model (`provider/model` format). |
| **AgentLoop** | Core execution engine driving the LLM ↔ tool multi-turn loop. |
| **ToolExecutor** | Tool registry and execution. Manages 14 tools (11 core + 3 skill discovery). |
| **LlmPlanner** | JSON-structured planning — decomposes complex tasks into execution plans with dependency graphs. |
| **WaveScheduler** | Groups independent plan steps into waves and executes them in parallel via `JoinSet`. |
| **AgentEvent** | `#[non_exhaustive]` event enum emitted during streaming — safe for SDK evolution. |

## Agent Loop

The core execution cycle. Each round:

1. **GenerateStart hook** fires — injection detector scans the prompt
2. **LLM call** — streaming to Anthropic or OpenAI-compatible API
3. **GenerateEnd hook** fires — output sanitizer redacts PII
4. If LLM returns `tool_use`:
   - **PreToolUse hook** fires — taint tracker and interceptor check for data leakage
   - **Permission check** — Deny → Allow → Ask → Default evaluation
   - **HITL confirmation** — if required, wait for user approval (with timeout)
   - **Guard policy** — defense-in-depth check on ToolExecutor
   - **Tool execution** — run the tool, capture output
   - **PostToolUse hook** fires — audit logging
5. Feed tool result back to LLM, go to step 1
6. If LLM returns text-only → done

Maximum rounds per generation configurable via `max_tool_rounds` (default: 50).

## Parallel Plan Execution

When planning is enabled, the `LlmPlanner` decomposes a complex task into steps with a dependency graph. The wave scheduler then executes independent steps concurrently:

```
User: "Refactor auth to use JWT and update all tests"
  │
  ▼  LlmPlanner decomposes into dependency graph
┌─────────────────────────────────────────────────┐
│  ExecutionPlan                                   │
│                                                  │
│  ┌──────────────┐  ┌──────────────────┐         │
│  │ s1: Analyze  │  │ s2: Analyze DB   │  Wave 1 │
│  │ auth module  │  │ schema           │ (parallel)
│  └──────┬───────┘  └────────┬─────────┘         │
│         │                   │                    │
│         └─────────┬─────────┘                    │
│                   ▼                              │
│         ┌─────────────────┐                      │
│         │ s3: Implement   │              Wave 2  │
│         │ JWT integration │                      │
│         └────────┬────────┘                      │
│                  ▼                               │
│         ┌─────────────────┐                      │
│         │ s4: Write tests │              Wave 3  │
│         └─────────────────┘                      │
└─────────────────────────────────────────────────┘
```

The scheduler loop:
1. `get_ready_steps()` → find steps with all dependencies `Completed`
2. Single step ready → execute sequentially (full history chain preserved)
3. Multiple steps ready → spawn all into `tokio::JoinSet` with cloned base history
4. Collect results → sort deterministically → merge into shared history
5. Failed steps → dependents become unreachable (deadlock detection breaks the loop)
6. Emit `GoalProgress` event after each wave

Each parallel step runs its own independent agent loop (LLM calls + tool execution). Results are merged via a sorted summary message so subsequent steps see all prior work.

## Defense-in-Depth Security

Five independent security layers, each capable of blocking a request:

| Layer | Component | What it does |
|-------|-----------|-------------|
| 1 | Permission Policy | Deny → Allow → Ask → Default rule evaluation with glob patterns |
| 2 | HITL Confirmation | Independent of permissions — even `Allow` goes through HITL check |
| 3 | Hook-based Security | SecurityGuard registers at priority 1 (highest): taint tracking, injection detection, output sanitization |
| 4 | Guard Policy | Defense-in-depth check on ToolExecutor before every execution |
| 5 | Skill Tool Filters | Per-skill `allowed_tools` restrictions enforced in agent loop |

## Context Management

When context usage exceeds the threshold (default 80% of model's context window):

1. Keep first 2 messages (system context)
2. Keep last 20 messages (recent context)
3. Summarize middle messages via LLM call
4. Insert summary as a synthetic message

This keeps the session within context limits while preserving important context.

## Subagent System

The `task` tool delegates work to child agents with restricted tool access:

| Agent Type | Available Tools | Use Case |
|------------|----------------|----------|
| `explore` | read, grep, glob, ls | Find code, understand structure |
| `general` | all except task | Complex multi-step tasks |
| `plan` | read, grep, glob, ls | Design implementation approach |

## Persistence

Three storage backends:

| Backend | Use case |
|---------|----------|
| `memory` | In-memory only, no persistence across restarts |
| `file` | JSON files in configured `sessions_dir` (default) |
| `custom` | Inject external store (PostgreSQL, Redis) |
