---
title: Code Generation
description: Generate responses and structured output with streaming support
---

import { Tab, Tabs } from 'fumadocs-ui/components/tabs';

# Code Generation

The generation APIs send messages to the LLM and return responses. For most use cases, prefer the [Agentic Loop](/docs/code/agentic) which handles tool execution automatically.

## Send (Non-Streaming)

<Tabs groupId="lang" items={['Rust (Native)', 'Python (Native)', 'Node.js (Native)', 'TypeScript (gRPC)', 'Python (gRPC)']}>
<Tab value="Rust (Native)">
```rust
let result = agent.send("What files are in the src/ directory?").await?;

println!("{}", result.text);                    // Assistant response
println!("Tools: {}", result.tool_calls_count); // Tool calls made
println!("Tokens: {}", result.usage.total_tokens);
```
</Tab>
<Tab value="Python (Native)">
```python
result = agent.send("What files are in the src/ directory?")

print(result.text)
print(f"Tools: {result.tool_calls_count}")
print(f"Tokens: {result.total_tokens}")
```
</Tab>
<Tab value="Node.js (Native)">
```typescript
const result = await agent.send('What files are in the src/ directory?');

console.log(result.text);
console.log(`Tools: ${result.tool_calls_count}`);
console.log(`Tokens: ${result.total_tokens}`);
```
</Tab>
<Tab value="TypeScript (gRPC)">
```typescript
const result = await client.generate(sessionId, [
  { role: 'user', content: 'What files are in the src/ directory?' },
]);

console.log(result.message.content);    // Assistant response text
console.log(result.toolCalls);          // Tool calls to execute client-side
console.log(result.usage.totalTokens);  // Token usage
console.log(result.finishReason);       // 'stop' | 'length' | 'tool_calls'
```
</Tab>
<Tab value="Python (gRPC)">
```python
result = await client.generate(session_id, [
    {"role": "user", "content": "What files are in the src/ directory?"},
])
print(result["message"]["content"])
print(result["usage"]["total_tokens"])
```
</Tab>
</Tabs>

## Stream

<Tabs groupId="lang" items={['Rust (Native)', 'Python (Native)', 'Node.js (Native)', 'TypeScript (gRPC)', 'Python (gRPC)']}>
<Tab value="Rust (Native)">
```rust
let (mut rx, handle) = agent.stream("Explain the auth module").await?;

while let Some(event) = rx.recv().await {
    match event {
        AgentEvent::TextDelta { text } => print!("{text}"),
        AgentEvent::ToolStart { name, .. } => println!("\nðŸ”§ {name}"),
        AgentEvent::ToolEnd { output, .. } => {
            println!("  â†’ {}", &output[..200.min(output.len())]);
        }
        AgentEvent::End { usage, .. } => {
            println!("\nâœ… {} tokens", usage.total_tokens);
        }
        _ => {}
    }
}
let result = handle.await??;
```
</Tab>
<Tab value="Python (Native)">
```python
for event in agent.stream("Explain the auth module"):
    if event.event_type == "text_delta":
        print(event.text, end="", flush=True)
    elif event.event_type == "tool_start":
        print(f"\nðŸ”§ {event.tool_name}")
    elif event.event_type == "tool_end":
        print(f"  â†’ {event.tool_output[:200]}")
    elif event.event_type == "end":
        print(f"\nâœ… {event.total_tokens} tokens")
```
</Tab>
<Tab value="Node.js (Native)">
```typescript
const events = await agent.stream('Explain the auth module');
for (const event of events) {
  if (event.type === 'text_delta') process.stdout.write(event.text);
  if (event.type === 'tool_start') console.log(`\nðŸ”§ ${event.tool_name}`);
  if (event.type === 'tool_end') console.log(`  â†’ ${event.tool_output?.slice(0, 200)}`);
  if (event.type === 'end') console.log(`\nâœ… ${event.total_tokens} tokens`);
}
```
</Tab>
<Tab value="TypeScript (gRPC)">
```typescript
for await (const chunk of client.streamGenerate(sessionId, [
  { role: 'user', content: 'Explain the auth module' },
])) {
  switch (chunk.type) {
    case 'content':
      process.stdout.write(chunk.content);
      break;
    case 'tool_call':
      console.log(`\nTool: ${chunk.toolCall.name}(${chunk.toolCall.arguments})`);
      break;
    case 'tool_result':
      console.log(`Result: ${chunk.toolResult.output}`);
      break;
    case 'done':
      console.log(`\nFinish: ${chunk.finishReason}`);
      break;
  }
}
```
</Tab>
<Tab value="Python (gRPC)">
```python
async for chunk in client.stream_generate(session_id, [
    {"role": "user", "content": "Explain the auth module"},
]):
    if chunk.get("content"):
        print(chunk["content"], end="", flush=True)
    if chunk.get("tool_call"):
        print(f"\nTool: {chunk['tool_call']['name']}")
```
</Tab>
</Tabs>

## Conversation History (Native)

Native mode supports multi-turn conversations by passing history:

<Tabs groupId="lang" items={['Rust', 'Python']}>
<Tab value="Rust">
```rust
use a3s_code_core::llm::Message;

let history = vec![
    Message::user("What's in src/?"),
    Message::assistant("The src/ directory contains main.rs and lib.rs."),
];

let result = agent.send_with_history(&history, "Now explain main.rs").await?;
let (rx, handle) = agent.stream_with_history(&history, "Refactor main.rs").await?;
```
</Tab>
<Tab value="Python">
```python
# Python native mode maintains internal conversation state
# Each send/stream call continues the conversation
result = agent.send("What's in src/?")
result = agent.send("Now explain main.rs")  # Continues from previous
```
</Tab>
</Tabs>

## Structured Output (gRPC)

Generate output conforming to a JSON Schema. Available in gRPC mode.

<Tabs groupId="lang" items={['TypeScript', 'Python']}>
<Tab value="TypeScript">
```typescript
const result = await client.generateStructured(sessionId, [
  { role: 'user', content: 'Analyze the complexity of src/auth.ts' },
], {
  schema: JSON.stringify({
    type: 'object',
    properties: {
      file: { type: 'string' },
      complexity: { type: 'string', enum: ['low', 'medium', 'high'] },
      lines: { type: 'number' },
      functions: {
        type: 'array',
        items: {
          type: 'object',
          properties: {
            name: { type: 'string' },
            complexity: { type: 'string' },
          },
        },
      },
    },
    required: ['file', 'complexity', 'lines', 'functions'],
  }),
});

const analysis = JSON.parse(result.data);
console.log(analysis.complexity);  // 'medium'
```
</Tab>
<Tab value="Python">
```python
import json

result = await client.generate_structured(session_id, [
    {"role": "user", "content": "Analyze the complexity of src/auth.ts"},
], schema=json.dumps({
    "type": "object",
    "properties": {
        "file": {"type": "string"},
        "complexity": {"type": "string", "enum": ["low", "medium", "high"]},
        "lines": {"type": "number"},
    },
    "required": ["file", "complexity", "lines"],
}))

analysis = json.loads(result["data"])
```
</Tab>
</Tabs>

## Event Types (Native)

| Event | Fields | Description |
|-------|--------|-------------|
| `start` | `prompt` | Generation started |
| `turn_start` | `turn` | New agent turn |
| `text_delta` | `text` | Text chunk from assistant |
| `tool_start` | `tool_id`, `tool_name` | Tool execution started |
| `tool_end` | `tool_id`, `tool_name`, `tool_output`, `exit_code` | Tool execution completed |
| `turn_end` | `turn`, `total_tokens` | Turn completed |
| `end` | `text`, `total_tokens` | Generation finished |
| `error` | `error` | Error occurred |

## Chunk Types (gRPC)

| Type | Fields | Description |
|------|--------|-------------|
| `content` | `content` | Text delta from assistant |
| `tool_call` | `toolCall` | Tool call request (id, name, arguments) |
| `tool_result` | `toolResult` | Tool execution result |
| `metadata` | `metadata` | Additional metadata |
| `done` | `finishReason` | Stream complete |

## RPCs (gRPC)

| RPC | Description |
|-----|-------------|
| `generate(sessionId, messages)` | Generate response (unary) |
| `streamGenerate(sessionId, messages)` | Generate response (streaming) |
| `generateStructured(sessionId, messages, schema)` | Generate structured output (unary) |
| `streamGenerateStructured(sessionId, messages, schema)` | Generate structured output (streaming) |
