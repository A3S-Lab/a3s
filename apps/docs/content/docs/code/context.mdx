---
title: Context Management
description: Context compaction and pluggable context providers for RAG
---

# Context Management

A3S Code provides two context management features: **automatic context compaction** when conversations grow long, and **pluggable context providers** for retrieval-augmented generation (RAG).

import { Steps, Step } from 'fumadocs-ui/components/steps';
import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

## Context Compaction

When context usage exceeds the threshold (default 80% of model's context window), the agent automatically summarizes the conversation to stay within limits.

### How It Works

<Steps>
<Step>Keep first 2 messages (system context)</Step>
<Step>Keep last 20 messages (recent context)</Step>
<Step>Summarize middle messages via LLM call</Step>
<Step>Insert summary as a synthetic message</Step>
</Steps>

This preserves important context while reducing token usage.

### Configuration

```rust
use a3s_code_core::SessionOptions;

let session = agent.session("/project", Some(
    SessionOptions::new()
        .with_context_threshold(0.8)  // Compact at 80% (default)
))?;
```

### Events

The agent emits events during compaction:

| Event | When |
|-------|------|
| `ContextWarning` | Context usage exceeds threshold |
| `ContextCompacting` | Compaction started |
| `ContextCompacted` | Compaction completed |

## Context Providers

Context providers inject additional information into the LLM's system prompt before each generation. This enables RAG (retrieval-augmented generation), memory recall, and integration with external knowledge bases.

### Overview

The agent queries registered context providers before each LLM call. Providers return `ContextItem` entries that are formatted as XML blocks and prepended to the system prompt:

```
System Prompt
├── Base instructions
├── Context blocks:          ← injected by context providers
│   ├── [resource] API docs for auth module
│   ├── [memory] User prefers TypeScript
│   └── [resource] Related code snippets
└── Tool definitions
```

Events are emitted during resolution: `ContextResolving` (with provider names) and `ContextResolved` (with total items and token count).

### ContextProvider Trait

```rust
#[async_trait]
pub trait ContextProvider: Send + Sync {
    /// Query this provider for relevant context
    async fn query(&self, query: ContextQuery) -> Result<ContextResult>;

    /// Optional: extract and store context after a turn completes
    async fn on_turn_complete(&self, _messages: &[Message]) -> Result<()> {
        Ok(()) // default no-op
    }
}
```

The `query()` method receives a `ContextQuery` and returns matching `ContextItem` entries. The optional `on_turn_complete()` hook allows providers to extract and store information from conversation turns (e.g., memory extraction).

### ContextQuery

| Field | Type | Description |
|-------|------|-------------|
| `query` | `String` | The search query (usually the user's prompt) |
| `context_types` | `Vec<ContextType>` | Types to retrieve |
| `depth` | `ContextDepth` | How much detail to return |
| `max_results` | `usize` | Maximum items to return |
| `max_tokens` | `usize` | Token budget for results |
| `session_id` | `Option<String>` | Scope results to a session |
| `params` | `HashMap<String, String>` | Provider-specific parameters |

Builder methods make construction ergonomic:

```rust
let query = ContextQuery::new("authentication flow")
    .with_types(vec![ContextType::Resource])
    .with_depth(ContextDepth::Overview)
    .with_max_results(5)
    .with_max_tokens(4000)
    .with_session_id("session-123");
```

#### ContextType

| Type | Description |
|------|-------------|
| `Memory` | Memory items (episodic, semantic, procedural, working) |
| `Resource` | External resources (files, docs, code) — default |

#### ContextDepth

| Depth | Token Budget | Description |
|-------|-------------|-------------|
| `Abstract` | ~100 tokens | Brief summary |
| `Overview` | ~2,000 tokens | Moderate detail (default) |
| `Full` | Variable | Complete content |

### ContextItem

| Field | Type | Description |
|-------|------|-------------|
| `id` | `String` | Unique item identifier |
| `context_type` | `ContextType` | Memory or Resource |
| `content` | `String` | The context content |
| `token_count` | `usize` | Estimated token count |
| `relevance` | `f32` | 0.0–1.0 relevance score |
| `source` | `Option<String>` | Where this context came from |
| `metadata` | `HashMap<String, String>` | Additional metadata |

Items are formatted as XML for injection into the system prompt via `to_xml()`.

## Built-in Provider: MemoryContextProvider

Bridges the [Memory](/docs/code/memory) system to the context provider interface. Performs semantic search over memory items and converts them to `ContextItem` entries with relevance scores.

```rust
use a3s_code_core::context::MemoryContextProvider;
use a3s_code_core::memory::MemoryManager;

let memory = Arc::new(MemoryManager::new());
let provider = Arc::new(MemoryContextProvider::new(memory));

let session = agent.session("/project", Some(
    SessionOptions::new().with_context_provider(provider)
))?;
```

## Custom Context Provider Example

```rust
use a3s_code_core::context::{ContextProvider, ContextQuery, ContextResult, ContextItem, ContextType};
use async_trait::async_trait;

struct DocsContextProvider {
    docs_path: PathBuf,
}

#[async_trait]
impl ContextProvider for DocsContextProvider {
    async fn query(&self, query: ContextQuery) -> Result<ContextResult> {
        // Search documentation files
        let matches = search_docs(&self.docs_path, &query.query)?;

        let items: Vec<ContextItem> = matches.into_iter()
            .map(|doc| ContextItem {
                id: doc.path.to_string_lossy().to_string(),
                context_type: ContextType::Resource,
                content: doc.content,
                token_count: doc.content.split_whitespace().count(),
                relevance: doc.score,
                source: Some(format!("docs:{}", doc.path.display())),
                metadata: HashMap::new(),
            })
            .collect();

        Ok(ContextResult { items })
    }
}

// Register with session
let provider = Arc::new(DocsContextProvider {
    docs_path: PathBuf::from("./docs"),
});

let session = agent.session("/project", Some(
    SessionOptions::new().with_context_provider(provider)
))?;
```

## Multiple Providers

Register multiple context providers to combine different sources:

```rust
let memory_provider = Arc::new(MemoryContextProvider::new(memory));
let docs_provider = Arc::new(DocsContextProvider { docs_path });
let code_provider = Arc::new(CodeContextProvider { repo_path });

let session = agent.session("/project", Some(
    SessionOptions::new()
        .with_context_provider(memory_provider)
        .with_context_provider(docs_provider)
        .with_context_provider(code_provider)
))?;
```

All providers are queried in parallel, and results are merged before injection into the system prompt.

## Best Practices

<Steps>
<Step>**Set token budgets** — Use `max_tokens` to prevent context overflow</Step>
<Step>**Filter by type** — Use `context_types` to retrieve only relevant context</Step>
<Step>**Adjust depth** — Use `Abstract` for summaries, `Full` for detailed content</Step>
<Step>**Implement relevance scoring** — Return items sorted by relevance (0.0–1.0)</Step>
<Step>**Use on_turn_complete** — Extract and store information from conversations</Step>
<Step>**Cache results** — Implement caching in your provider to reduce latency</Step>
</Steps>

## Events

Context-related events emitted during streaming:

| Event | When |
|-------|------|
| `ContextResolving` | Context providers queried |
| `ContextResolved` | Context items retrieved |
| `ContextWarning` | Context usage exceeds threshold |
| `ContextCompacting` | Compaction started |
| `ContextCompacted` | Compaction completed |

See [Sessions](/docs/code/sessions) for full event reference.

## API Reference

### SessionOptions

| Option | Rust | Python | Node.js | Default |
|--------|------|--------|---------|---------|
| FS context | `.with_fs_context(path)` | `fs_context=path` | `fsContext: path` | `None` |
| Custom provider | `.with_context_provider(Arc::new(p))` | _(config-based)_ | _(config-based)_ | `None` |
| Compact threshold | `.with_context_threshold(f)` | `context_threshold=f` | `contextThreshold: f` | `0.8` |

### ContextProvider trait (Rust)

| Method | Signature | Description |
|--------|-----------|-------------|
| `retrieve` | `async fn retrieve(&self, query: &ContextQuery) -> Result<Vec<ContextItem>>` | Fetch relevant context items |
| `on_turn_complete` | `async fn on_turn_complete(&self, turn: &TurnSummary) -> Result<()>` | Called after each agent turn |
| `name` | `fn name(&self) -> &str` | Provider identifier |

### ContextQuery fields

| Field | Type | Description |
|-------|------|-------------|
| `query` | `String` | Natural language query |
| `max_tokens` | `Option<usize>` | Token budget for results |
| `context_types` | `Vec<ContextType>` | Filter by type |
| `depth` | `ContextDepth` | `Abstract` or `Full` |

### ContextItem fields

| Field | Type | Description |
|-------|------|-------------|
| `content` | `String` | Context text |
| `source` | `String` | Origin (file path, memory ID, etc.) |
| `relevance` | `f32` | Relevance score (0.0–1.0) |
| `context_type` | `ContextType` | `File`, `Memory`, `Skill`, `Custom` |

### VectorContextConfig (Rust)

| Method | Description | Default |
|--------|-------------|---------|
| `VectorContextConfig::new(path)` | Set workspace root | — |
| `.with_min_relevance(f)` | Minimum cosine similarity | `0.3` |
| `.with_max_results(n)` | Max chunks per query | `10` |
| `.with_chunk_size(n)` | Max chars per chunk | `1500` |
