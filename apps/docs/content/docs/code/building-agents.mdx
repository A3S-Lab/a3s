---
title: "Case Study: Building A3S Deep"
description: How to build a complex agentic application using A3S Code â€” a deep research agent with autonomous decision-making, streaming, and user interaction
---

import { Tab, Tabs } from 'fumadocs-ui/components/tabs';

# Building a Complex Agent with A3S Code

This guide walks through how [A3S Deep](https://github.com/A3S-Lab/Deep) â€” a fully autonomous deep research agent â€” is built on top of A3S Code. It demonstrates real-world patterns for session management, structured output, streaming events, the decide-act-observe loop, skills, delegation, and user interaction.

## What A3S Deep Does

A3S Deep takes a research question and autonomously:

1. **Clarifies** ambiguity via LLM + user interaction
2. **Plans** by decomposing into sub-questions with search queries
3. **Researches** using a decide-act-observe loop (search, verify, compare, follow citations)
4. **Synthesizes** findings into a structured report
5. **Renders** output in multiple formats (Markdown, JSON, Word, PDF, PPT)

The entire system is built on a single dependency: `@a3s-lab/code`.

## Project Setup

```bash
mkdir my-agent && cd my-agent
bun init
bun add @a3s-lab/code
```

```typescript
import { A3sClient, createProvider } from '@a3s-lab/code';
import type { Session, AgentLoopEvent, StepResult } from '@a3s-lab/code';
```

## 1. Session Creation

Every agent starts by creating a session with an LLM provider and system prompt.

```typescript
const client = new A3sClient({ address: 'localhost:4088' });
const provider = createProvider({
  name: 'anthropic',
  apiKey: process.env.ANTHROPIC_API_KEY!,
});

const session = await client.createSession({
  model: provider('claude-sonnet-4-20250514'),
  workspace: '/path/to/workspace',
  system: `You are a deep research agent. You have access to web search,
file tools, and analysis capabilities. Always be factual, cite sources,
and produce structured outputs.`,
});
```

The session handles all LLM calls, tool execution, and context management. A3S Code's built-in tools (web search, file read/write, bash) are available immediately.

## 2. Structured Output with Schemas

A3S Deep uses `generateObject()` extensively to get typed, structured LLM responses. Define a JSON Schema and the LLM returns validated data.

### Planning: Decompose a question into sub-questions

```typescript
const PLAN_SCHEMA = JSON.stringify({
  type: 'object',
  properties: {
    originalQuestion: { type: 'string' },
    approach: { type: 'string' },
    subQuestions: {
      type: 'array',
      items: {
        type: 'object',
        properties: {
          id: { type: 'number' },
          question: { type: 'string' },
          searchQueries: { type: 'array', items: { type: 'string' } },
          priority: { type: 'string', enum: ['high', 'medium', 'low'] },
        },
        required: ['id', 'question', 'searchQueries', 'priority'],
      },
    },
  },
  required: ['originalQuestion', 'approach', 'subQuestions'],
});

const { object: plan } = await session.generateObject<ResearchPlan>({
  schema: PLAN_SCHEMA,
  prompt: `Decompose this research question into 3-5 focused
sub-questions with specific search queries.

Research question: "${question}"`,
});

// plan.subQuestions is typed and validated
for (const sq of plan.subQuestions) {
  console.log(`[${sq.priority}] ${sq.question}`);
  console.log(`  Queries: ${sq.searchQueries.join(', ')}`);
}
```

### Clarification: Determine if user input is needed

```typescript
const { object: parsed } = await session.generateObject<{
  needsClarification: boolean;
  reason: string;
  questions: Array<{ question: string; options: string[] }>;
}>({
  schema: CLARIFY_SCHEMA,
  prompt: `Analyze whether this question is ambiguous or too broad.
Research question: "${question}"`,
});

if (parsed.needsClarification) {
  // Ask user for clarification
  const answers = await askUser(parsed.questions);
  // Refine question with answers
}
```

## 3. Agent Loop with Tool Streaming

The core research loop uses `session.send()` which triggers the server-side agentic loop â€” the LLM calls tools (web search, file read), and you receive real-time events.

```typescript
const result = await session.send(
  `Research the following question by searching the web.

Question: "${question}"
Search queries:
  - "${queries[0]}"
  - "${queries[1]}"

After searching, extract key findings with URL, title, key points,
and a relevance score (0.0-1.0).`,
  {
    // Real-time tool call events
    onEvent: (event: AgentLoopEvent) => {
      if (event.type === 'tool_call') {
        console.log(`ðŸ”§ ${event.toolName}(${JSON.stringify(event.args)})`);
      }
      if (event.type === 'tool_result') {
        console.log(`   â†’ ${event.output.slice(0, 100)}`);
      }
    },
    // Per-step token tracking
    onStepFinish: (step: StepResult) => {
      if (step.usage) {
        totalTokens.input += step.usage.promptTokens ?? 0;
        totalTokens.output += step.usage.completionTokens ?? 0;
      }
    },
  },
);

// result.text contains the agent's final response
const findings = extractFindings(result.text);
```

## 4. The Decide-Act-Observe Pattern

A3S Deep implements an autonomous agent loop where the LLM decides the next action at each step.

### Action Types

```typescript
type ActionType =
  | 'search'           // Web search for a sub-question
  | 'deep_read'        // Read a specific URL in depth
  | 'verify'           // Cross-reference a claim
  | 'compare'          // Side-by-side analysis of findings
  | 'follow_citation'  // Follow a citation chain
  | 'replan'           // Revise the research plan
  | 'synthesize'       // Write the final report
  | 'ask_user'         // Ask the user a question
  | 'delegate';        // Spawn parallel research branches
```

### Decider: LLM chooses the next action

```typescript
class Decider {
  constructor(
    private session: Session,
    private availableActions: ActionType[],
  ) {}

  async decide(stateManager: ResearchStateManager): Promise<AgentAction> {
    const context = stateManager.getDecisionContext();

    const { object: decision } = await this.session.generateObject<AgentAction>({
      schema: DECIDE_SCHEMA,
      prompt: `You are the decision engine for a research agent.
Based on the current state, choose the single most valuable next action.

Available actions: [${this.availableActions.join(', ')}]

Current state:
${context}

Rules:
1. Choose "synthesize" when confidence >= 80%.
2. Prefer "search" for under-covered sub-questions.
3. Use "verify" when contradictions exist.
4. Use "delegate" only when 3+ independent questions remain.`,
    });

    return decision;
  }
}
```

### Action Executor: Handler registry pattern

```typescript
class ActionExecutor {
  private handlers = new Map<ActionType, ActionHandler>();

  register<A extends AgentAction>(type: A['type'], handler: ActionHandler<A>) {
    this.handlers.set(type, handler as ActionHandler);
  }

  async execute(action: AgentAction, ctx: ExecutionContext): Promise<ActionResult> {
    const handler = this.handlers.get(action.type);
    if (!handler) throw new Error(`No handler for: ${action.type}`);
    return handler(action, ctx);
  }
}

// Register handlers
const executor = new ActionExecutor();

executor.register<SearchAction>('search', async (action, ctx) => {
  const { findings } = await ctx.analyzer.searchAndAnalyze(
    action.subQuestionId,
    action.question,
    action.queries,
    (event) => { /* stream tool calls to UI */ },
    (step) => { /* track token usage */ },
  );
  return { action, findings, relations: [] };
});

executor.register<VerifyAction>('verify', async (action, ctx) => {
  // Search for corroborating evidence
  const searchResult = await ctx.session.send(
    `Search for evidence that supports or contradicts: "${action.claim}"`,
  );
  // Generate structured verdict
  const { object: verdict } = await ctx.session.generateObject<Verdict>({
    schema: VERDICT_SCHEMA,
    prompt: `Evaluate this claim based on search results...`,
  });
  return { action, findings, relations };
});
```

### The Main Loop

```typescript
const budget = maxIterations * (plan.subQuestions.length + 2);
let step = 0;

while (step < budget) {
  step++;

  // DECIDE: LLM picks the next action
  const action = await decider.decide(stateManager);
  console.log(`[Step ${step}] ${action.type}: ${action.reasoning}`);

  // ACT: Execute via handler registry
  const result = await executor.execute(action, ctx);

  // OBSERVE: Integrate findings into state
  stateManager.integrate(result);

  // Terminal condition
  if (action.type === 'synthesize') break;
}
```

## 5. Skills System

Load custom skills from the filesystem. Skills extend the agent's capabilities via prompt injection.

```typescript
async function loadSkills(session: Session, skillsDir: string) {
  const entries = fs.readdirSync(skillsDir, { withFileTypes: true });

  for (const entry of entries) {
    if (!entry.isDirectory()) continue;
    const skillFile = path.join(skillsDir, entry.name, 'SKILL.md');
    if (!fs.existsSync(skillFile)) continue;

    const content = fs.readFileSync(skillFile, 'utf-8');
    await session.loadSkill(entry.name, content);
  }
}

// Load skills from .a3s/skills/
await loadSkills(session, '.a3s/skills');
```

A3S Deep uses skills for output rendering â€” `report-word`, `report-pdf`, `report-ppt` are skills that transform the research report into different formats.

## 6. Parallel Delegation

When multiple independent sub-questions remain under-covered, spawn parallel research branches:

```typescript
class BranchManager {
  constructor(
    private session: Session,
    private ui: TerminalUI,
    private maxParallel: number = 3,
  ) {}

  async delegate(subQuestions: SubQuestion[]): Promise<Finding[]> {
    // Run up to maxParallel branches concurrently
    const batches = chunk(subQuestions, this.maxParallel);
    const allFindings: Finding[] = [];

    for (const batch of batches) {
      const results = await Promise.all(
        batch.map((sq) =>
          this.session.send(
            `Research: "${sq.question}"\nQueries: ${sq.queries.join(', ')}`,
          ),
        ),
      );

      for (const result of results) {
        allFindings.push(...extractFindings(result.text));
      }
    }

    return allFindings;
  }
}
```

## 7. Token Tracking via Session Proxy

Wrap the session with a Proxy to automatically track token usage from every LLM call:

```typescript
function wrapSessionForTokenTracking(session: Session, onTokens: (usage: TokenUsage) => void): Session {
  return new Proxy(session, {
    get(target, prop, receiver) {
      const value = Reflect.get(target, prop, receiver);
      if (typeof value !== 'function') return value;

      // Auto-track tokens for generateText/generateObject calls
      if (prop === 'generateText' || prop === 'generateObject') {
        return async (...args: any[]) => {
          const result = await value.apply(target, args);
          if (result?.usage) {
            onTokens({
              input: result.usage.promptTokens ?? 0,
              output: result.usage.completionTokens ?? 0,
            });
          }
          return result;
        };
      }

      return value.bind(target);
    },
  });
}

const tracked = wrapSessionForTokenTracking(session, (usage) => {
  console.log(`+${usage.input} in, +${usage.output} out`);
});
```

## 8. Real-Time User Interaction

A3S Deep supports three interaction modes. The key pattern is a Promise-based bridge between the agent pipeline and user input:

```typescript
class AskUser {
  private pendingResolve: ((value: string) => void) | null = null;

  /** Ask user a question, returns a Promise that resolves when they answer */
  async chat(message: string, phase: string): Promise<string | null> {
    return new Promise((resolve) => {
      this.pendingResolve = resolve;
      // Display message in UI, wait for input
      this.ui.showPrompt(message);
    });
  }

  /** Called by UI when user submits input */
  onUserInput(text: string) {
    if (this.pendingResolve) {
      this.pendingResolve(text);
      this.pendingResolve = null;
    }
  }
}
```

### Control Lane: Real-time steering

Users can inject directives at any point during research via a priority queue:

```typescript
class ControlLane {
  private queue: UserDirective[] = [];

  /** Drain all pending directives (called between steps) */
  drain(): UserDirective[] {
    const directives = [...this.queue];
    this.queue = [];
    return directives;
  }

  /** Parse user command into directive */
  parseCommand(input: string): UserDirective | null {
    if (input.startsWith('/focus ')) return { type: 'focus', content: input.slice(7) };
    if (input.startsWith('/add '))   return { type: 'add_query', content: input.slice(5) };
    if (input.startsWith('/stop'))   return { type: 'stop', content: '' };
    if (input.startsWith('/skip'))   return { type: 'skip', content: '' };
    return { type: 'chat', content: input };
  }
}

// In the main loop, check control lane between steps:
while (step < budget) {
  const directives = control.drain();
  for (const d of directives) {
    if (d.type === 'stop') break;
    if (d.type === 'focus') stateManager.focusOn(d.content);
    if (d.type === 'chat') {
      const reply = await session.generateText({
        prompt: `User says: "${d.content}". Respond briefly.`,
      });
      ui.info(reply.text);
    }
  }

  // ... decide, act, observe
}
```

## 9. Session Cleanup

Always dispose of the session when done:

```typescript
try {
  // ... run research pipeline
  return report;
} finally {
  await session[Symbol.asyncDispose]();
}
```

## Architecture Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    A3S Deep                         â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Planner â”‚  â”‚ Decider â”‚  â”‚ ActionExecutor    â”‚  â”‚
â”‚  â”‚ clarify â”‚  â”‚ decide  â”‚  â”‚ search, verify,   â”‚  â”‚
â”‚  â”‚ plan    â”‚  â”‚ next    â”‚  â”‚ compare, delegate â”‚  â”‚
â”‚  â”‚ reflect â”‚  â”‚ action  â”‚  â”‚ deep_read, replan â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚            â”‚                â”‚              â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                    â”‚                                â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚            â”‚  A3S Session  â”‚                       â”‚
â”‚            â”‚ .send()       â”‚â† Agent loop events    â”‚
â”‚            â”‚ .generateText â”‚â† Structured output    â”‚
â”‚            â”‚ .generateObj  â”‚â† Token tracking       â”‚
â”‚            â”‚ .loadSkill()  â”‚â† Skills loading       â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                    â”‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              @a3s-lab/code                          â”‚
â”‚  Web Search Â· File Tools Â· Bash Â· Context Â· Memory â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The key insight: **A3S Code handles all the infrastructure** (LLM calls, tool execution, context management, streaming) while the application layer focuses purely on domain logic (research planning, decision-making, finding extraction, report synthesis).
