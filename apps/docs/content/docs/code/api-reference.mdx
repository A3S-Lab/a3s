---
title: API Reference
description: Complete library API reference â€” Agent, Session, Events, Tools, and Configuration
---

import { Tab, Tabs } from 'fumadocs-ui/components/tabs';

# API Reference

A3S Code is a library-first SDK. All functionality is accessed through the `Agent` and `AgentSession` types.

## Agent

The entry point. Created from a config file or inline config string.

<Tabs groupId="lang" items={['Rust', 'TypeScript', 'Python']}>
<Tab value="Rust">
```rust
use a3s_code_core::{Agent, SessionOptions};

// From config file (.hcl or .json)
let agent = Agent::new("agent.hcl").await?;

// From inline config string (JSON or HCL, auto-detected)
let agent = Agent::new(r#"{"defaultModel": "anthropic/claude-sonnet-4-20250514", ...}"#).await?;

// From CodeConfig struct
let agent = Agent::from_config(config).await?;
```
</Tab>
<Tab value="TypeScript">
```typescript
const { Agent } = require('@a3s-lab/code');

// From config file (.hcl or .json)
const agent = await Agent.create('agent.hcl');

// From inline JSON string
const agent = await Agent.create('{"defaultModel": "anthropic/claude-sonnet-4-20250514", ...}');
```
</Tab>
<Tab value="Python">
```python
from a3s_code import Agent

# From config file (.hcl or .json)
agent = Agent.create("agent.hcl")

# From inline JSON string
agent = Agent.create('{"defaultModel": "anthropic/claude-sonnet-4-20250514", ...}')
```
</Tab>
</Tabs>

## AgentSession

Created from an Agent, bound to a workspace directory. All LLM and tool operations happen on the session.

<Tabs groupId="lang" items={['Rust', 'TypeScript', 'Python']}>
<Tab value="Rust">
```rust
// Default session
let session = agent.session("/my-project", None)?;

// With model override
let session = agent.session("/my-project", Some(
    SessionOptions::new()
        .with_model("openai/gpt-4o")
))?;
```
</Tab>
<Tab value="TypeScript">
```typescript
// Default session
const session = agent.session('/my-project');

// With model override
const session = agent.session('/my-project', {
  model: 'openai/gpt-4o',
});
```
</Tab>
<Tab value="Python">
```python
# Default session
session = agent.session("/my-project")

# With model override
session = agent.session("/my-project", model="openai/gpt-4o")
```
</Tab>
</Tabs>

## Session Methods

### `send(prompt)` â€” Non-Streaming Generation

Sends a prompt to the LLM and runs the agent loop (tool execution included). Returns the final result.

<Tabs groupId="lang" items={['Rust', 'TypeScript', 'Python']}>
<Tab value="Rust">
```rust
let result = session.send("What files handle authentication?").await?;
// result.text, result.tool_calls_count, result.usage.total_tokens
```
</Tab>
<Tab value="TypeScript">
```typescript
const result = await session.send('What files handle authentication?');
// result.text, result.toolCallsCount, result.totalTokens
```
</Tab>
<Tab value="Python">
```python
result = session.send("What files handle authentication?")
# result.text, result.tool_calls_count, result.total_tokens
```
</Tab>
</Tabs>

### `stream(prompt)` â€” Streaming Generation

Sends a prompt and returns real-time events as the agent loop runs.

<Tabs groupId="lang" items={['Rust', 'TypeScript', 'Python']}>
<Tab value="Rust">
```rust
// AgentEvent is #[non_exhaustive] â€” always include a wildcard arm
let (mut rx, _handle) = session.stream("Explain the auth module").await?;
while let Some(event) = rx.recv().await {
    match event {
        AgentEvent::TextDelta { text } => print!("{text}"),
        AgentEvent::ToolCall { name, .. } => println!("\nðŸ”§ {name}"),
        AgentEvent::End { usage, .. } => { println!("\nâœ… {} tokens", usage.total_tokens); break; }
        _ => {} // required: AgentEvent is #[non_exhaustive]
    }
}
```
</Tab>
<Tab value="TypeScript">
```typescript
const events = await session.stream('Explain the auth module');
for (const event of events) {
  if (event.type === 'text_delta') process.stdout.write(event.text);
  if (event.type === 'tool_start') console.log(`\nðŸ”§ ${event.toolName}`);
  if (event.type === 'tool_end') console.log(`  â†’ ${event.toolOutput?.slice(0, 100)}`);
  if (event.type === 'end') console.log(`\nâœ… ${event.totalTokens} tokens`);
}
```
</Tab>
<Tab value="Python">
```python
for event in session.stream("Explain the auth module"):
    if event.event_type == "text_delta":
        print(event.text, end="", flush=True)
    elif event.event_type == "tool_start":
        print(f"\nðŸ”§ {event.tool_name}")
    elif event.event_type == "tool_end":
        print(f"  â†’ {event.tool_output[:100]}")
    elif event.event_type == "end":
        print(f"\nâœ… {event.total_tokens} tokens")
```
</Tab>
</Tabs>

### `send_with_history(history, prompt)` â€” Multi-Turn (Rust)

Continue a conversation with explicit history:

```rust
use a3s_code_core::llm::Message;

let history = vec![
    Message::user("What's in src/?"),
    Message::assistant("The src/ directory contains main.rs and lib.rs."),
];

let result = session.send_with_history(&history, "Now explain main.rs").await?;
```

### `tool(name, args)` â€” Direct Tool Execution

Call tools directly without going through the LLM:

<Tabs groupId="lang" items={['Rust', 'TypeScript', 'Python']}>
<Tab value="Rust">
```rust
let result = session.tool("bash", serde_json::json!({"command": "cargo test"})).await?;
println!("[{}] {}", result.exit_code, result.output);
```
</Tab>
<Tab value="TypeScript">
```typescript
const result = await session.tool('bash', { command: 'cargo test' });
console.log(`[${result.exitCode}] ${result.output}`);
```
</Tab>
<Tab value="Python">
```python
result = session.tool("bash", {"command": "cargo test"})
print(f"[{result['exit_code']}] {result['output']}")
```
</Tab>
</Tabs>

### Convenience Wrappers

<Tabs groupId="lang" items={['Rust', 'TypeScript', 'Python']}>
<Tab value="Rust">
```rust
session.read_file("src/main.rs").await?;
session.bash("cargo test").await?;
session.glob("**/*.rs").await?;
session.grep("fn main").await?;
session.tool("write", serde_json::json!({"path": "x.rs", "content": "..."})).await?;
```
</Tab>
<Tab value="TypeScript">
```typescript
await session.readFile('src/main.rs');
await session.bash('cargo test');
await session.glob('**/*.rs');
await session.grep('fn main');
await session.tool('write', { path: 'x.rs', content: '...' });
```
</Tab>
<Tab value="Python">
```python
session.read_file("src/main.rs")
session.bash("cargo test")
session.glob("**/*.rs")
session.grep("fn main")
session.tool("write", {"path": "x.rs", "content": "..."})
```
</Tab>
</Tabs>

## Return Types

### AgentResult

Returned by `send()`.

<Tabs groupId="lang" items={['Rust', 'TypeScript', 'Python']}>
<Tab value="Rust">
```rust
pub struct AgentResult {
    pub text: String,
    pub tool_calls_count: usize,
    pub usage: TokenUsage,
}

pub struct TokenUsage {
    pub prompt_tokens: usize,
    pub completion_tokens: usize,
    pub total_tokens: usize,
}
```
</Tab>
<Tab value="TypeScript">
```typescript
interface AgentResult {
  text: string;
  toolCallsCount: number;
  promptTokens: number;
  completionTokens: number;
  totalTokens: number;
}
```
</Tab>
<Tab value="Python">
```python
class AgentResult:
    text: str
    tool_calls_count: int
    prompt_tokens: int
    completion_tokens: int
    total_tokens: int
```
</Tab>
</Tabs>

### AgentEvent

Emitted by `stream()`.

<Tabs groupId="lang" items={['Rust', 'TypeScript', 'Python']}>
<Tab value="Rust">
```rust
#[non_exhaustive]  // always include _ => {} in match
pub enum AgentEvent {
    Start { prompt: String },
    TurnStart { turn: usize },
    TextDelta { text: String },
    ToolCall { id: String, name: String },
    ToolResult { id: String, name: String, output: String, exit_code: i32 },
    ToolOutputDelta { id: String, name: String, delta: String },
    TurnEnd { turn: usize, usage: TokenUsage },
    End { text: String, usage: TokenUsage },
    ConfirmationRequired { tool_id: String, tool_name: String, description: String },
    Error { message: String },
    // ... future variants may be added
}
```
</Tab>
<Tab value="TypeScript">
```typescript
interface AgentEvent {
  type: 'start' | 'text_delta' | 'tool_start' | 'tool_end'
      | 'tool_output_delta' | 'turn_start' | 'turn_end'
      | 'end' | 'confirmation_required' | 'error';
  text?: string;
  toolName?: string;
  toolId?: string;
  toolOutput?: string;
  exitCode?: number;
  turn?: number;
  prompt?: string;
  description?: string;
  error?: string;
  totalTokens?: number;
}
```
</Tab>
<Tab value="Python">
```python
class AgentEvent:
    event_type: str       # "start", "text_delta", "tool_start", etc.
    text: str | None
    tool_name: str | None
    tool_id: str | None
    tool_output: str | None
    exit_code: int | None
    turn: int | None
    prompt: str | None
    description: str | None  # For confirmation_required
    error: str | None
    total_tokens: int | None
```
</Tab>
</Tabs>

### ToolCallResult

Returned by `tool()`.

<Tabs groupId="lang" items={['Rust', 'TypeScript', 'Python']}>
<Tab value="Rust">
```rust
pub struct ToolCallResult {
    pub name: String,
    pub output: String,
    pub exit_code: i32,
}
```
</Tab>
<Tab value="TypeScript">
```typescript
interface ToolResult {
  name: string;
  output: string;
  exitCode: number;
}
```
</Tab>
<Tab value="Python">
```python
# Returns a dict
{"name": str, "output": str, "exit_code": int}
```
</Tab>
</Tabs>

### SessionOptions

<Tabs groupId="lang" items={['Rust', 'TypeScript', 'Python']}>
<Tab value="Rust">
```rust
pub struct SessionOptions {
    pub model: Option<String>,  // "provider/model" format
}

// Builder:
// SessionOptions::new().with_model("openai/gpt-4o")
```
</Tab>
<Tab value="TypeScript">
```typescript
interface SessionOptions {
  model?: string;  // "provider/model" format
}
```
</Tab>
<Tab value="Python">
```python
# Keyword arguments to agent.session():
# model="provider/model"
```
</Tab>
</Tabs>

> **Note:** `skill_dirs` and `agent_dirs` are configured at the agent level via `CodeConfig`, not per-session.

## Event Types

| Event | Fields | Description |
|-------|--------|-------------|
| `start` | `prompt` | Generation started |
| `turn_start` | `turn` | New agent turn |
| `text_delta` | `text` | Text chunk from assistant |
| `tool_start` | `tool_id`, `tool_name` | Tool execution started |
| `tool_end` | `tool_id`, `tool_name`, `tool_output`, `exit_code` | Tool execution completed |
| `tool_output_delta` | `tool_id`, `tool_name`, `text` | Tool output increment |
| `turn_end` | `turn`, `total_tokens` | Turn completed |
| `end` | `text`, `total_tokens` | Generation finished |
| `confirmation_required` | `tool_id`, `tool_name`, `description` | HITL confirmation needed |
| `error` | `error` | Error occurred |

## Configuration

### HCL Format (Preferred)

```hcl
# === LLM (required) ===
default_model = "anthropic/claude-sonnet-4-20250514"

# === Agent Behavior ===
max_tool_rounds  = 20          # default: 50
thinking_budget  = 4096        # reasoning token budget

# === Extensions ===
skill_dirs = ["./skills"]      # *.md skill files
agent_dirs = ["./agents"]      # *.yaml/*.md agent files

# === Storage ===
storage_backend = "file"       # "memory" | "file" | "custom"
sessions_dir    = "/tmp/a3s"   # session persistence path
storage_url     = "redis://localhost:6379"

# === Providers ===
providers {
  name    = "anthropic"
  api_key = "sk-ant-..."

  models {
    id          = "claude-sonnet-4-20250514"
    name        = "Claude Sonnet 4"
    family      = "claude-sonnet"
    tool_call   = true
    temperature = true
    reasoning   = false
    cost {
      input       = 3.0
      output      = 15.0
      cache_read  = 0.3
      cache_write = 3.75
    }
    limit {
      context = 200000
      output  = 8192
    }
  }
}

providers {
  name    = "openai"
  api_key = "sk-..."

  models {
    id        = "gpt-4o"
    name      = "GPT-4o"
    tool_call = true
  }

  models {
    id        = "gpt-4o-proxy"
    name      = "GPT-4o (via Proxy)"
    api_key   = "sk-proxy-key..."                 # per-model override
    base_url  = "https://proxy.example.com/v1"    # per-model override
    tool_call = true
  }
}
```

Provider-level `api_key` and `base_url` are defaults. Model-level values override them. See [Providers](/docs/code/providers) for details.

### Config Options

| Field | HCL | JSON | Type | Default |
|-------|-----|------|------|---------|
| Default model | `default_model` | `defaultModel` | `string` | â€” (required, `provider/model` format) |
| Max tool rounds | `max_tool_rounds` | `maxToolRounds` | `int?` | `50` |
| Thinking budget | `thinking_budget` | `thinkingBudget` | `int?` | `null` |
| Skill dirs | `skill_dirs` | `skillDirs` | `string[]` | `[]` |
| Agent dirs | `agent_dirs` | `agentDirs` | `string[]` | `[]` |
| Storage backend | `storage_backend` | `storageBackend` | `string` | `"file"` |
| Sessions dir | `sessions_dir` | `sessionsDir` | `string?` | `null` |
| Storage URL | `storage_url` | `storageUrl` | `string?` | `null` |

## Built-in Tools (14)

### Core Tools (11)

| Tool | Purpose |
|------|---------|
| `bash` | Execute shell commands |
| `read` | Read files with line numbers |
| `write` | Create/overwrite files |
| `edit` | String replacement editing |
| `patch` | Apply unified diff patches |
| `grep` | Search file contents (ripgrep) |
| `glob` | Find files by pattern |
| `ls` | List directory contents |
| `web_fetch` | Fetch web content |
| `web_search` | Search the web |
| `cron` | Manage scheduled tasks |

### Skill Discovery Tools (3)

| Tool | Purpose |
|------|---------|
| `search_skills` | Search GitHub for available skills |
| `install_skill` | Install a skill from GitHub |
| `load_skill` | Load and register an installed skill |

See [Built-in Tools](/docs/code/tools) for detailed parameter schemas.
