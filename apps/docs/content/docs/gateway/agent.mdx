---
title: Agent Extensions
description: AI-specific features including multi-platform webhooks, privacy routing, and token metering
---

# Agent Extensions

A3S Gateway includes AI-specific extensions for agent orchestration, multi-platform webhook normalization, privacy-aware routing, token metering, and conversation affinity.

## Channel Webhooks

Normalize incoming webhooks from 7 messaging platforms into a unified format:

```rust
pub enum ChannelType {
    Telegram,
    Slack,
    Discord,
    Feishu,
    DingTalk,
    WeCom,
    WebChat,
}

pub struct ChannelMessage {
    pub channel: ChannelType,
    pub user_id: String,
    pub content: String,
    pub timestamp: i64,
}
```

Each platform's webhook payload is parsed and normalized into `ChannelMessage`, allowing backend services to handle all platforms with a single interface.

### Supported Platforms

| Platform | Webhook Format | Features |
|----------|---------------|----------|
| Telegram | JSON (Bot API) | Text, commands, inline queries |
| Slack | JSON (Events API) | Messages, slash commands, interactions |
| Discord | JSON (Interactions) | Messages, slash commands |
| Feishu | JSON (Event Subscription) | Messages, card actions |
| DingTalk | JSON (Robot) | Text, markdown, action cards |
| WeCom | XML/JSON (Callback) | Text, events |
| WebChat | JSON (custom) | Generic web chat interface |

## Privacy-Aware Routing

Route requests to different backends based on content privacy classification:

```rust
pub enum PrivacyLevel {
    Public,
    Internal,
    Confidential,
    Secret,
}
```

The privacy router inspects request content and classifies it using keyword matching (delegated to `a3s_privacy::KeywordMatcher`). Based on the classification, requests are routed to appropriate backends:

- **Public** → Standard cloud backends
- **Internal** → Internal network backends
- **Confidential** → On-premise backends
- **Secret** → TEE-protected backends (A3S Box with SEV-SNP)

## Token Metering

Track and limit LLM token usage with sliding window counters:

```rust
pub struct TokenMeter {
    // Sliding window token limits per:
    // - user
    // - agent
    // - session
    // - global
}
```

Token metering enables:
- Per-user token budgets (e.g., 100K tokens/day)
- Per-agent rate limiting
- Session-level token tracking
- Global throughput limits
- Usage reporting for billing

## Conversation Affinity

Maintain session stickiness for multi-turn conversations:

```rust
pub struct ConversationAffinity {
    // Header and cookie-based sticky sessions
    // TTL and eviction
}
```

Ensures that all requests within a conversation are routed to the same backend agent, preserving context and state. Affinity is tracked via:
- Custom headers (e.g., `X-Conversation-Id`)
- Cookies
- Configurable TTL with automatic eviction

## Agent Health Probe

Extended health checking for AI agent backends:

```rust
pub struct AgentHealthProbe {
    // Model loading state detection
}
```

Detects agent-specific states beyond simple HTTP health:

| State | Description |
|-------|-------------|
| `Loading` | Model is loading into memory |
| `Ready` | Agent is ready to accept prompts |
| `Busy` | Agent is processing (at capacity) |
| `Error` | Agent encountered an error |
| `Unreachable` | Agent is not responding |

Backends in `Loading` or `Busy` state can be temporarily excluded from load balancing without being marked unhealthy.

## Request Priority

Classify and prioritize requests for quality-of-service:

```rust
pub enum Priority {
    Critical,
    High,
    Normal,
    Low,
    BestEffort,
}
```

Priority is determined by:
- Request headers (e.g., `X-Priority`)
- User tier (premium vs. free)
- Path patterns (e.g., `/api/realtime` → Critical)

Higher-priority requests are served first when backends are at capacity.
